<h1>Metodologia oceny rozwiązania</h1>


<p>
    Należy przywołać cel rozwiązania, którym jest optymalizacja płynności nieograniczonej i swobodnej wizualnej
    eksploracji danych pomiarowych w webowych interfejsach użytkownika.
</p>
<p>
    W związku z powyższym rozwiązanie to należy ocenić w różnych aspektach, które są przedstawione i omówione w
    kolejnych podrozdziałach.
</p>

<h2>Aspekt użyteczności</h2>
<p>
    Oceniając użyteczność rozwiązania, należy zwrócić uwagę na jej psychologiczny charakter.
    Skoro celem jest poprawa satysfakcji użytkowaników eksplorujących dane pomiarowe, to odpowiedź na pytanie, czy
    ten cel został zrealizowany, będzie można pozyskać tylko i wyłącznie pozyskując subiektywne oceny reprezentatywnej
    grupy tych użytkowników.
    W istocie, satysfakcja, zniecierpliwienie, ciągłość myśli, rozproszenie - są to zjawiska niemierzalne, zachodzące w
    psychice ludzkiej.
    Nie istnieje zatem żaden wzór, który bez pytania użytkowników o zdanie, odpowiedziałby na pytanie, czy rozwiązanie
    rzeczywiście jest lepsze od innego.
</p>
<p>
    W związku z tym, by sformułować rzetelną ocenę użyteczności, należy posłużyć się statystyką i zebrać opinie wśród
    grupy użytkowników, którzy będą mogli w praktyce użyć gotowego rozwiązania i porównać je z referencyjną
    implementacją rozwiązania uchodzącego za typowe, tj. bez żadnych zaproponowanych optymalizacji.
</p>
<h3>Wyzwanie z pozyskaniem opini</h3>
<p>
    Problemem z pozyskaniem takich opinii jest zapewnienie wiarygodności odpowiedzi udzielanych przez respondentów, tym
    bardziej, że będą pytani o swoje odczucia, które ciężko kwestionować, które w danej chwili mogą być zaburzone.
    Z drugiej strony, niełatwo jest stworzyć takie warunki badawcze, w których można mieć pewność, że odczucia
    respondenta, choć
    subiektywne i niepodważalne, ukierunkowane są na działanie rzetelnie porównanych i zrozumianych rozwiązań będących
    przedmiotem tej subiektywnej oceny.
</p>
<h4>Sugerowanie się kolejnością przedstawianych rozwiązań</h4>

<p>
    Istnieje niebezpieczeństwo, że kolejność prezentowanych rozwiązań może silnie wpływać na sposób udzielenia
    odpowiedzi, zwłaszcza, gdy w badaniu ocenia się poszczególne rozwiązania względem siebie.

    Na przykład, w artykule <em>Challenges and Recommendations for Assessing User Experiences</em> <a
        href="#bib:lallemand2017lab"></a> zauważono, że kolejność, w którym prezentowane są rozwiązania (systemy)
    wpływała na doświadczenia użytkownika w ten sposób, że różnica w postrzeganiu dwóch systemów jest większa, gdy
    "lepsze" rozwiązanie zostanie pokazane w pierwszej kolejności.

    Z drugiej strony, by uniknąć sugestywności w ankiecie i przedstawiać poszczególne rozwiązania w sposób losowy, może
    to doprowadzić do utraty logicznej spójności poszczególnego badania, tym samym zmieszania, zagubienia, w końcu
    zniechęcenia respondenta.
</p>

<p>
    Innym argumentem przemawiającym za ustaloną kolejnością prezetnowanych rozwiązań jest fakt, iż przedmiot badań w
    niniejszej pracy może być trudny do pojęcia przez respondenta bez wytłumaczenia mu, dlaczego prezentowane jest mu
    kolejne rozwiązanie, które w pierwszej chwili wydaje się być identycze do poprzedniego. W związku z tym w badaniu
    respondent będzie informowany, co zostało ulepszone w kolejnej wersji, i będzie miał on odpowiedzieć, w jakim
    stopniu się zgadza ze stwierdzeniem, że prezentowane rozwiązanie faktycznie jest lepsze od poprzedniego.
</p>


<ul helper>
    Mogą bowiem oni :
    * sugerować się kolejnością przestawianych rozwiązań
    * nie zrozumieć, na czym polega zadanie
    * udzielać nieprawdziwe lub nieprzemyślane odpowiedzi
    * nie poradzić sobie z obsługą interakcji z komponentem, w konsekwencji zminimalizować obszar działania, na którym
    mogliby wyrobić swoje zdanie (nie wyklika na tyle duzo zeby moc zauwazyc ewentualne roznice w dzialaniu)
    * zostać zniechęceni dużą liczbą zadan
    <li>
        weryfikować, czy użytkownik wiedział co robić w ankiecie (recording)
    </li>
    <li>dobrze zakreślić, czego chcemy od użytkownika, który nie musi mieć pojęcia o danych/komputerze</li>
    <li>użytkownicy którzy korzystają z tego typu interfejsu, niekoniecznie są znawcami IT</li>
    <li>grono odbiorców - kto może odpowiedzieć na pytania i jakie może mieć problemy</li>
    <li>sprawdzenie, czy jest korelacja między oceną wersji a histogramem sesji</li>
    <li>warto też dać możliwość wyrażenia swojego odczucia o sposobie badania - możemy się dowiedzieć, czy ktoś się
        znużył (i sprawdzić czy bawił się wykresami)
    </li>
    <li>weryfikacja -będzie to można potem potwierdzić histogramem oraz pytaniami końcowymi jak pytania otwarte, znużenie, etc</li>
    <li>na koniec - pierwsza runka ankiety w trybie nadzorowanym - pewność, że stworzone narzędzie badawcze nakieruje na
        to co trzeba i nie narzuci odczuć
    </li>
</ul>

<h2>podsumowanie wymagań</h2>
<p helper>
    w kilku punktach, jakie wymagania stawiamy aplikacji explorejs-survey żeby spełniła nasze kryteria metodologiczne

</p>