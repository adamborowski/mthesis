<h1 id="chapter:theoretical">Podstawowe informacje</h1>
<h2>Wizualizacja danych</h2>
<ul class="helper">
    <li>Definicja</li>
    <li>Jest to całościowo ujęty proces przekazu danych kończący się na kształtowanie obrazu w umyśle odbiorcy</li>
</ul>

<h2>Interaktywna analiza wizualna</h2>
<ul class="helper">
    <li>Co to jest interaktywna analiza wizualna</li>
    <li>Co to jest wizualna eksporacja (nawigacja)</li>
    <li>Nawigacja w celu uzyskania odpowiedzi na pytania (gdzieś fajne bib na to było)</li>
    <li>doczytać jak systemy pomagają podczas takiej analizy - np podkreślają ważne fragmenty - można tutaj pochwalić
        się MedCharts
    </li>
</ul>
<h2>Dane pomiarowe</h2>
<ul class="helper">
    <li>Co to są dane pomiarowe i jak się je opisuje</li>
    <li>Co to jest akwizycja danych - wspomnieć o np rejestratorach nox</li>
    <li>Co to są agregacje danych i jak różne branże je tworzą (max i kierunek wiatru, liczba alarmów, wystąpienie
        faktu, malowanie częstotliwości (jakis portal do muzyki był), min-max-avg, 5-50-95 percentyl, ogólnie percentyle
    </li>
    <li>Przykłady zastosowania danych pomiarowych (WIOŚ, medyczne, cała  tabelka)</li>
</ul>
<p>
    Wiele firm i organizacji na całym świecie pozyskuje petabajty danych i umieszcza je w prywatnych lub publicznych
    chmurach.
    Jednym z rodzajów tych danych są serie czasowe pochodzące z różnych źródeł, takich jak sieci sensorowe, inteligentne
    sieci elektroenergetyczne czy rynki finansowe.
    Ciągle zwiększające swoją objętość serie czasowe przechowywane są w mniej lub bardziej wyspecjalizowanych
    relacyjnych bazach danych.
    Bazy te z kolei wykorzystywane są jako źródło danych w aplikacjach umożliwiajych ich wizualną analizę.
    W związku z interakcją analitykow z aplikacją wykonywane są zapytania do relacyjnej bazy danych przechowującej
    oryginalne serie czasowe <a href="#bib:data-aggregation"></a>.

</p>
<p>
    Dane pomiarowe <trans lang="ang">Scientific Data</trans> <a href="#bib:scientific-data-dictionary"></a> są to dane
    reprezentujące stan obserwowanego obiektu w przestrzeni czasu.
    Zbierane są określoną metodą, w określonym celu.
    Ich wykorzystanie zakłada systematyczny pomiar wartości, niekiedy wykonywany z dużą częstotliwością.

    Dane reprezentowane są w postaci serii czasowej, gdzie każda próbka oznaczona jest stemplem czasowym oraz zbiorem
    atrybutów zmiennych zależnych, zazwyczaj liczbowych <a href="#bib:Hauser12VisTutorial"></a>.

    W tabeli <a href="#table:exampleTimeSerie"></a> pokazano przykładowy fragment serii czasowej danych pomiarowych
    pewnego silnika tłokowego próbkowane co 1 sekundę. Można z nich wyczytać między innymi kiedy zaszło interesujące
    zdarzenie, oraz że przy starcie silnika temperatura osiągnęła wysoki poziom co prawdopodobnie było przyczyną
    jego awaryjnego wyłączenia.

    <figure type="table" id="table:exampleTimeSerie">
        <figcaption>Przykładowy szereg czasowy</figcaption>
        <table class="small align-content-right align-table-center">
            <thead>
            <tr>
                <th>stempel czasowy</th>
                <th>temperatura [&deg;C]</th>
                <th>prędkość [obr/min]</th>
                <th>stan pracy</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td>2015-08-08 10:36:00.000</td>
                <td>28</td>
                <td>0</td>
                <td>wyłączony</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:01.000</td>
                <td>28</td>
                <td>0</td>
                <td>wyłączony</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:02.000</td>
                <td>50</td>
                <td>500</td>
                <td>pracuje</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:03.000</td>
                <td>80</td>
                <td>1000</td>
                <td>pracuje</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:04.000</td>
                <td>100</td>
                <td>2000</td>
                <td>pracuje</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:05.000</td>
                <td>200</td>
                <td>300</td>
                <td>awaria</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:07.000</td>
                <td>90</td>
                <td>0</td>
                <td>awaria</td>
            </tr>
            <tr>
                <td>2015-08-08 10:36:08.000</td>
                <td>40</td>
                <td>0</td>
                <td>wyłączony</td>
            </tr>
            </tbody>
        </table>
    </figure>
</p>

<p>
    Regularnie zbierane dane pomiarowe dotarczają ogólne informacje o obserwowanym obiekcie, umożliwiają jego kontrolę,
    ale również pozwalają dokładnie zbadać pojedyncze incydenty.

    Dane są zazwyczaj pochodzenia naturalnego, wymagają więc specjalnych urządzeń potrafiących mierzyć te obiekty.
    Przykładowym urządzeniem pomiarowym mogą być pokazane na rysunku <a href="#picture:analizator"></a> analizatory
    parametrów jakości powietrza, takich jak tlenków azotu, tlenków siarki, pyłów, benzenu czy ozonu.

    W zależności od celu pomiaru próbkowanie odbywa się ze zróżnicowaną częstotliwością &mdash; od kilku milisekund do
    kilku godzin.

    Na przykłd w przypadku monitoringu jakości powietrza w Polsce, próbkowanie odbywa się z częstotliwością 10 sekund.

    Cały proces fizycznego uzyskiwania danych pomiarowych, transmisji, i wstępnego przetwarzania nazywa się akwizycją
    danych.

    Aby ukazać skalę tych danych, w tabeli <a href="#table:measurementDataExamples"></a> pokazano przykłady i użycia
    danych pomiarowych.


</p>
<figure type="picture" class="on-right" id="picture:analizator">
    <figcaption>Wyposażenie stacji monitoringu jakości powietrza Wojewódzkiego Inspektoratu Ochrony Środowiska
    </figcaption>
    <img src="/images/stacja–monitoringu.png" style="height:8cm;">
</figure>

<figure type="table" id="table:measurementDataExamples">
    <figcaption>Przykłady danych pomiarowych. Wielkość próbki zależeć może od liczby atrybutów pomiaru i formatu ich
        przechowywania i transmisji.
    </figcaption>
    <table>
        <thead>
        <tr>
            <th>Dziedzina</th>
            <th>Przykładowe użycie danych</th>
            <th>Przykładowa wielkość próbki</th>
            <th>Średnia częstotliwość emisji</th>
            <th>Dane do przetworzenia</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>lotnictwo</td>
            <td>szukanie przyczyny katastrofy wśród 90 parametrów 8-godzinnego lotu</td>
            <td>8B</td>
            <td>1Hz</td>
            <td>90 &times; 8h &times; 1Hz &times; 8B = 24.74MB</td>
        </tr>
        <tr>
            <td>badania operacyjne</td>
            <td>obserwacja stanu systemu kolejkowego w ciągu tygodnia</td>
            <td>64B</td>
            <td>50Hz</td>
            <td>7d &times; 50Hz &times; 64B = 2GB</td>
        </tr>
        <tr>
            <td>medycyna</td>
            <td>wizualizacja okresu jednego tygodnia 8 parametrów medycznych</td>
            <td>8B</td>
            <td>200Hz</td>
            <td>8 &times; 7d &times; 200Hz &times; 8B = 7.21 GB</td>
        </tr>
        <tr>
            <td>monitoring środowiska</td>
            <td>wizualizacja okresu 5 lat 8 parametrów jakości powietrza</td>
            <td>200B</td>
            <td>0.1Hz</td>
            <td>8 × 5y × 0.1Hz × 200B = 25GB</td>
        </tr>
        </tbody>
    </table>
</figure>

<h3>Agregowanie danych</h3>
<p>
    W najnowocześniejszych narzędziach wizualnej analizy takich jak Tableau, QlikView czy SAP Lumira, zapytania o dane
    pomiarowe do bazy danych zakładają stosunkowo mały rozmiar zwróconej odpowiedzi.

    Jednak, gdy mowa o odczycie danych wielkoskalowych, odpowiedź bazy danych może zawierać miliony punktów.

    To powoduje wysokie obciążenie łącza pomiędzy aplikacją użytkownika a bazą danych.

    W przypadku zastosowań zaprezentowanych w tabeli <a href="#table:measurementDataExamples"></a>, każdy użytkownik
    musiałby oczekiwać na załadowanie odpowiednio 24MB, 2GB, 7GB oraz 25GB danych, zanim system będzie mógł
    zwizualizować te dane w postaci wykresu.

    Ze względu na rosnącą popularność oraz szybki wzrost liczby źródeł danych o wysokiej częstotliwości próbkowania,
    powyższe obserwacje można uznać za problem dotyczący nie tylko pojedynczego użytkownika, ale wszystkich
    użytkowników podłączonych do wspólnej sieci Internet <a href="#bib:data-aggregation"></a>.

</p>
<p>
    Wizualizacja takich danych jest w naturalny sposób ograniczona pikselami wyświetlającymi obszar wykresu o danej
    wysokości i szerokości. Ograniczeniem jest też rozdzielczość ludzkiego oka, którą szacuje się na blisko 576
    megapikseli <a href="#bib:eye-resolution"></a>, zatem nie istnieje możliwość wizualizacji danych bez ograniczeń.

    Te cechy implikują fakt, iż zanim dane zwrócone w odpowiedzi bazy danych ukształtują się w umyśle odbiorcy,
    dokonywana jest ich redukcja polegająca na pewnym ich przekształceniu oraz późniejszej projekcji na raster o
    ustalonej wysokości i serokości.

    Ta redukcja jest dokonywana naturalnie, niezależnie od implementacji aplikacji wizualizacyjnej czy wielkości zbioru
    wynikowego.
</p>
<p>
    Biorąc pod uwagę wyżej opisaną naturalną redukcję danych w procesie wizualizacji, dzisiejsze systemy dokonują tej
    redukcji wcześniej, już na etapie akwizycji danych.

    Redukcja ta polega na zastosowaniu odpowiednich funkcji agregujących na podzbiorach danych o stałym interwale.

    Tak przgotowane wcześniej dane wykorzystuje się jako dane wejściowe do opisanej wyżej naturalnej redukcji, co
    skutkuje identycznym rezultatem, jak pokazano na rysunku <a href="#picture:aggregation-reduction"></a> w punkcie a&nbsp;i&nbsp;b.

    Korzyścią z zastosowanie wcześniejszej redukcji jest niewątpliwie minimalizacja transmisji danych z bazy danych do
    aplikacji użytkownika.

    Rozwiązuje to tym samym problem obciążenia sieci.


</p>
<p>
    Z agregowaniem wizualizowanych danych wiążą się inne wyzwania.

    Pierwszym z nich jest odpowiednie dobranie wielkości interwału agregacji.

    Jeżeli interwał agregacji po zrzutowaniu na ekran będzie zajmował więcej niż jeden piksel, redukcja będzie
    zauważalna przez użytkownika i zinterpretowana jako rozmycie obrazu. Na rysunku <a
        href="#picture:aggregation-reduction"></a> w punkcie <i>c</i> pokazano, jak użytkownik widzi obraz, gdy dochodzi
    do
    wyświetlenia zbyt dużej agregacji danych.

    Drugim problemem jest zapewnienie odpowiedniej agregacji danych dla dowolnego zapytania do bazy danych.

    W tym celu systemy akwizycji danych agregują dane na różnych poziomach, aby baza danych mogła przesyłać jak
    najmniejszą liczbę punktow przy jednoczesnym zachowaniu redukcji identycznej z redukcją naturalną.
</p>
<figure type="picture" id="picture:aggregation-reduction">
    <figcaption>Wpływ agregacji na wizualizację danych. Dobrze dobrana agregacja nie zmienia rezultatu jednocześnie
        minimalizując rozmiar odpowiedzi bazy danych. Źle dobrana - powoduje zauważalną redukcję.
    </figcaption>
    <img src="cache/aggregation-and-natural-reduction.png">
</figure>
<p>
    W zależności od sposobu wizualizacji, systemy niekiedy dokonują dodatkowej agregacji w celu zwiększenia
    czytelności. W takim wypadku funkcja agregująca ma na celu wydobycie charakterystycznych dla danego celu
    wizualizacji cech, najlepiej opisujących to, co się działo z monitorowanym obiektem w agregowanym okresie.

    Poniżej zostały po krótce omówione różne metody agregowania danych i sposoby ich wykorzystania.
</p>
<h4>Próbkowanie</h4>
<h4>Ekstrema oraz średnia wartości skalarnych</h4>
<figure type="picture" id="picture:min-max-aggr">
    <figcaption>Wykorzystanie ekstremum oraz średniej w prezentacji agregowanych danych</figcaption>
    <img style="width:5cm;" src="/images/min-max.png"/>
</figure>
<!--Minimum, maksimum oraz wartość średnia to najbardziej podstawowy sposób agregowania danych.-->
<h4>Percentyle</h4>
<!--max i kierunek wiatru, liczba alarmów, wystąpienie
        faktu, malowanie częstotliwości (jakis portal do muzyki był), min-max-avg, 5-50-95 percentyl, ogólnie percentyle-->
<h4>Maksimum oraz kierunek wartości wektorowych</h4>
<h4>Wystąpienie faktu</h4>
<h4>Częstotliwość</h4>


<h2>Aplikacje rozproszone</h2>
<ul class="helper">
    <li>Czym jest aplikacja rozproszona</li>
    <li>Wątki, procesy, węzły</li>
    <li>Przykłady: gridy, klastry, jednostki specjalistyczne (XeonPHI, GPU), WWW, systemy czasu rzeczywistego, wirtualne
        zespoły robocze, automatyczne sterowanie
    </li>
    <li>optymalizacja aplikacji rozproszonych - cache + prefetch</li>
</ul>
<h2>Aplikacje internetowe</h2>
<ul class="helper">
    <li>Jest to typ aplikacji rozproszonej ale nie HiPerf, Xeon Phi itd</li>
    <li>Co to jest aplikacja internetowa</li>
    <li>Jakie są architektury takich aplikacji</li>
    <li>Przykłady takich aplikacji</li>
    <li>problemy skalowalności, REST</li>
</ul>
<h2>Interfejsy Webowe</h2>
<ul class="helper">
    <li>Ewolucja WWW do aplikacji interntowych</li>
    <li>Ewolucja desktopów do aplikacji przeglądarkowych</li>
    <li>JavaScript</li>
    <li>Ajax</li>
    <li></li>
</ul>
<h2>User Experience</h2>
<h2>Sztuczna inteligencja</h2>
<ul class="helper">
    <li>Czym jest sztuczna inteligencja</li>
    <li>Jak ona może pomóc w UX i interakcji z seriami czasowymi?</li>
    <!--uwaga - w pracy nie będzie użycia sztucznej inteligencji, wspomnieć, że kierunek rozwoju to np model predykcji oparty o rozproszone głębokie uczenie-->
</ul>
<h2>Systemy informacji przestrzennej</h2>
<h2>Algebra przedziałów</h2>
<h2>Big Data</h2>
<!--nie wiem czy to nie do imlpementacji-->