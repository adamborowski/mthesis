<h1 id="chapter:analysis">Analiza problemu</h1>

<p>
    Zagadnienie prezentacji w tej pracy dotyczy płynnego, swobodnego i nieograniczonego przeglądania ogromnej ilości
    danych na wykresie liniowym z osią czasu.
</p>


<!--TODO dać przykład jaki to wykres-->

<div>

    <p>
        Ograniczenia i wyzwania można śmiało porównać do systemów mapowych. Dla przykładu, w systemie <em>Google
        Maps </em>
        odwiedzić możesz każde miejsce na ziemi. Za pomocą kilku intuicyjnych ruchów możesz oddalić się od pomnika
        Neptuna
        w Gdańsku, by zobaczyć całą mapę Świata, następnie przyjżeć się z bliska Liberty Island w Nowym Jorku. Wyzwaniem
        w
        takim systemie jest zapewnienie, aby użytkownik w ogóle nie musiał czekać na fragmenty map, które chce oglądać,
        bo
        przecież nikt nie ładuje z sieci Internet szczegółowych obrazów satelitarnych całej kuli ziemskiej.
    </p>
    <p>
        W przypadku danych pomiarowych, można powiedzieć, że problem jest nieco prostszy, ponieważ nie poruszamy się po
        przestrzeni dwuwymiarowej, ale tylko po wymiarze czasu, który układa się na poziomej osi wykresu.
        Niemniej jednak zapewnienie wysokiej rozdzielczości obrazu na wykresie stanowi wyzwanie, jeżeli chcemy, by
        użytkownik jak najrzadziej był zmuszony czekać na doładowanie potrzebnych danych.
        Według <a href="https://www.nngroup.com/articles/response-times-3-important-limits/" target="blank">
        Nielsena</a>,
        oczekiwanie na odpowiedź systemu trwające powyżej 0.1 sekundy jest zauważalne i gdy się wydłuża &mdash; znacznie
        obniża się efektywność pracy.
    </p>
</div>,
<div class="text-justify">
    <h3 class="display-3">Wprowadzenie
        <small> merytoryczne</small>
    </h3>
    <p>
        Zagadnienie pochodzi z pogranicza czterech dziedzin:
    </p>
    <ul>
        <li><em>Wizualnej eksploracji danych</em>, bo chodzi o umożliwienie przeglądania wykresów serii
            czasowych, na przykład pomiaru stężenia dwutlenku siarki na urządzeniu pomiarowym lub parametrów pracy serca
            chorego pacjenta.
        </li>
        <li><em>Big Data</em>, ponieważ danych do eksploracji jest napawdę wiele. Na tyle dużo, że ich przetworzenie
            stanowi wyzwanie technologiczne i analityczne.
        </li>
        <li><em>Aplikacji internetowych</em>, ponieważ wykresy te mają być prezentowane w przeglądarce użytkownika,
            która
            łączy się ze zdalnym serwerem poprzez sieć komputerową.
        </li>
        <li><em>User Experience</em>, czyli aspektu użyteczności i efektywności korzystania z interfejsu interaktywnego.
        </li>
    </ul>

</div>,
<div class="text-justify">
    <h3 class="display-3">Przypadek użycia </h3>
    <p>
        Wyobraź sobie, że pracujesz nad analizą zjawisk pogodowych w ostatnich kilkudzesięciu latach.
        Chcesz w swojej przeglądarce internetowej przeglądać, w postaci wykresu liniowego, dane pięciu parametrów z
        urządzenia pomiarowego: wilgotności, tempertatury, prędkości wiatru, stężenia dwutlenku węgla i ozonu.
    </p>
    <p>
        Załóżmy, że z punktu widzenia badawczego zasadne jest, aby brać pod uwagę ostatnie pięćdziesiąt lat pomiarów
        wykonywanych z częstotliwością co 10 sekund.
        Dodatkowo załóżmy, że w analizie wartościowe jest zarówno przeglądanie większych zakresów danych by wysnuć
        generalne wnioski
        oraz przeglądanie poszczególnych incydentów.
    </p>
    <p>
        Policzmy, jak dużo danych potrzebnych jest do przetworzenia:
    </p>
    <pre>
        5 paramterów &times; 50 lat &times; 1/(10s) = 788.4 milionów punktów pomiarowych
    </pre>
    <p>
        Jeśli założyć, że każdy punkt wymaga zapisania daty powstania próbki oraz wartości pomiaru, to na zapisanie
        pojedynczego punktu potrzeba 12 bajtów (8 bajtów na datę w formacie <strong>long</strong> oraz 4 bajty na
        wartość
        w
        formacie
        zmiennoprzecinkowym).
    </p>
    <p>
        Biorąc pod uwagę liczbę punktów pomiarowych oraz rozmiar danych pojedynczego punktu,
        do przetworzenia jest aż <strong>9.5 GB danych</strong>
    </p>
    <p>
        Przy dobrym (100Mbps) łączu załadowanie tych danych do przeglądarki zajmie około <strong>13 minut</strong>.
        Nawet, jeśli każemy czekać użytkownikowi taki czas na pobranie tych danych z sieci do pamięci podręcznej
        komputera, to wyrysowanie miliarda punktów na wykresie niewątpliwie doprowadzi do awaryjnego zakończenia
        działania
        przeglądarki.
    </p>
</div>,
<div>
    <h3 class="display-3">Identyfikacja problemu</h3>
    <p>
        Być może zastanawiasz się, po co właściwie ładować te wszystkie dane? Przecież mózg ludzki nie jest w stanie
        przeanalizować każdego z miliarda punktów z osobna.
    </p>
    <p>
        Tutaj trzeba przywołać jeden istotny aspekt funkcjonalny zagadnienia.
        Otóż chcemy dać użytkownikowi swobodę nawigacji po wykresie, żeby mógł oglądać dane w
        dowolnym interesującym go zakresie i w odpowiednim przybliżeniu.
        To znaczy, że użytkownik powinien mieć dostęp do wszystkich danych.
        Nawigacja powinna odbywać się w sposób <strong>płynny i nieograniczony</strong>, tak jak to ma miejsce w
        nowoczesnych systemach mapowych.
    </p>
    <p>
        Faktycznie, ze wspomnianych wcześniej względów nie jest możliwe zbudowanie aplikacji, która pobiera wszystkie
        dane
        na początku,
        i je wszystkie potem wyświetla. Wykreślenie milionów punktów też zajmuje sporą część mocy obliczeniowej
        komputera
        użykownika. Takie rozwiązanie po prostu się nie nadaje do dużych zbiorów danych (nie skaluje się).
    </p>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania</h3>
    <p>
        Popularnym podejściem, które adresuje problem skalowalności, jest pobieranie z serwera tylko takiego zakresu
        danych, który ma być widoczny w danej chwili na ekranie, żeby uniknąć ładowania wszystkich danych.
    </p>
    <p>
        Nasuwa się pytanie, co w momencie, gdy użytkownik chciałby obejrzeć z grubsza jakiś duży zakres czasu? A może
        chciałby zobaczyć
        wszystkie dane "z lotu ptaka"?
        W tej sytuacji problem pojawia się z powrotem - potrzeba załadować wszystkie dane do przeglądarki.
    </p>
    <p>
        Warto zauważyć, że ze względu na pikselową konstrukcję monitorów graficznych, liczba punktów potrzebnych do
        poprawnego wyrysowania fragmentu danych ograniczona jest w pewnym sensie liczbą pikseli wyświetlacza. Zresztą -
        rozdzielczść ludzkiego oka też jest ograniczona.
        W związku z powyższym - użytkownik i tak jest w stanie tylko obejrzeć pewną uproszczoną formę danych, nie do
        końca
        nawet zdając sobie z tego sprawę dzięki zdolności abstrackcji i generalizacji.

    </p>
    <p>
        Dla przykładu, jeżeli na typowym monitorze chcemy obejrzeć nasze dane w zakresie jednego roku, to liczba punktów
        pomiarowych (około 3 miliony) znacznie przekracza liczbę pikseli w poziomie (około 2 tysiące).
        Zagęszczenie punktów na jednym rzędzie pikseli wyniesie kilka tysięcy.
        Takie zagęszczenie danych na ekranie jest zupełnie niepotrzebne, ze względu na wspomniane właśnie ograniczenia
        rozdzielczości
        monitora i ludzkiego oka.
    </p>
    <p>
        To naturalne ograniczenie wykorzystuje się w optymalizacji wspomnianego wcześniej problemu.
        Otóż zakłada się, że oprócz tego, że z serwera są pobierane tylko chwilowo potrzebne fragmenty danych, pobiera
        się je w
        formie maksymalnie uproszczonej. Nie za prostej, by nie było to zauważone przez ludzkie oko, ale takiej, by
        zminimalizować wielkość przesyłanych danych. Rozmiar ładowanych danych będzie więc związany z liczbą rzędów
        pikseli w
        poziomie &mdash; tym samym niezależny od wielkości zakresu czasu.
    </p>
    <p>
        Pozostaje jeszcze zadać sobie pytanie, czym właściwie jest to uproszczenie?
    </p>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; agregacje</small>
    </h3>
    <p>
        Uproszczona forma danych w naszym przypadku dotyczy tak na prawdę uproszczenia konkretnego piksela wyświetlanego
        wykresu.
        Przy dużym zagęszczeniu danych wiele punktów danych zostaje wyrysowanych na tym samym pionie piskeli, jak
        pokazano
        na rysunku poniżej.

    </p>
    <figure type="picture" id="picture:analysis/simplification">
        <figcaption>
            Gdy na jeden piksel przypada dużo punktów do wyświetlenia (po lewej), to i tak monitor wyświetli to
            jako pionowy słupek obejmujący występujące w tym pikselu wartości (po prawej).
        </figcaption>
        <img src="/images/analysis/simplification.png"/>
    </figure>
    <p>
        W związku z tym, uproszczoną formą danych będzie taka forma, która daje ten sam efekt na ekranie, ale będzie
        opisywała tylko taki pionowy "słupek" opisujący zakres wartości w danej kolumnie pikseli.
        W tym celu wprowadza się pojęcie <strong>agregacji danych</strong>.
    </p>
    <p>
        W tym przypadku agregacja to pewna struktura danych opisująca generalne cechy grupy danych z pewnego zakresu.
        Do obliczenia agregacji wykorzystuje się <em>agregaty</em> - funkcje matematyczne wyliczjące określoną
        statystykę.
        W tego typu systemach popularnymi agregatami są minimum, maksimum oraz wartość średnia.
    </p>
    <p>
        Przykład agregacji:
    </p>
    <blockquote>
        W sierpniu 2017 maksymalna temperatura wyniosła 33&deg;C, minimalna 15&deg;C, a średnia 21.34&deg;C.
    </blockquote>
    <p>
        Jest to zbiór, który w prosty i zwięzły sposób opisuje najważniejsze ogólne cechy zakresu pomiarów
        dokonanych w sierpniu 2017.
    </p>
    <p>
        Tego typu agregacja jest uproszczoną formą danych. Nie oznacza to, że może być wykorzystana w dowolnym momencie.
        Najlepiej ją wykorzystać dla takiej skali wykresu, gdzie będzie ona mieściła się na jednym pionie pikselów
        ekranu.
        Gdy będzie większa - uproszczenie będzie już zauważalne dla ludzkiego oka.
    </p>
    <p>
        Poniżej pokazano ten sam zakres danych, gdy zostały dobrane odpowiednie uproszczenia danych, oraz gdy zastosuje
        się
        zbyt duże uproszczenia. <strong>Uwaga</strong> - należy patrzeć na cieniowany obszar wykresu.
    </p>
    <figure  type="picture" id="picture:analysis/per-pixel">
        <figcaption>przykład agregacji o dopasowanej długości, mniejszej niż piksel - nie widać uproszczenia
        </figcaption>
        <img src="/images/analysis/per-pixel.png"/>
    </figure>
    <figure  type="picture" id="picture:analysis/sparse">
        <figcaption>przykład źle dobranej agregacji, większej niż jeden piksel - uproszczenie zauważalne dla ludzkiego
            oka
        </figcaption>
        <img src="/images/analysis/sparse.png"/>
    </figure>
    <p>
        Podsumowując - popularne podejście umożliwia swobodną i nieograniczoną eksplorację wielkich zbiorów, ponieważ
        minimalizuje komunikację między przeglądarką a serwerem stosujac takie uproszczenia, by nie zmniejszało
        dokładności danych wyświetlanych na wykresie.
    </p>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; serwer danych</small>
    </h3>
    <p>
        Warunkiem koniecznym tego rozwiązania jest, aby serwer na każde żądanie mógł odpowiedzieć w bardzo krótkim
        czasie.
        W tym celu serwer musi obliczyć agregacje (formy uproszczone), zanim zostanie o nie poproszony, ponieważ
        obliczenie agregacji dla większych zakresów może trwać zbyt długo.
    </p>
    <p>
        Serwer danych trzyma w specjalnie przygotowanej bazie dane oryginalne (generowane co 10s) (tutaj 9.5GB) oraz
        wyliczone agregacje
        o różnych wielkościach, na przykład
        <em> 30s</em>,
        <em> 1m</em>,
        <em> 3m</em>,
        <em> 10m</em>,
        <em> 30m</em>,
        <em> 1h</em>,
        <em> 4h</em>,
        <em> 8h</em>,
        <em> 12h</em>,
        <em> 1d</em>,
        <em> 7d</em>,
        <em> 30d</em>,
        <em> 90d</em>,
        <em> 1y</em>
        .
    </p>
    <p>
        Ważne jest, by tak dobrać wielkości agregacji, by dla każdego możliwego przybliżenia (skali) wykresu można było
        żądać dane o takiej wielkości agregacji, by odpowiadały blisko, lecz nie więcej niż jednemu pionu pikselów.
        Gdyby tak nie było, trzeba by było żądać mniejszych agregacji, co spowoduje niepotrzebnie zbyt dużą gęstość
        danych
        do wyrysowania na ekranie.
        Z kolei jeśli agregacja nie zmieściła by się w jednym rzędzie pikseli, będzie to widoczne jako reprezentacja
        danych niskiej rozdzielczości.
    </p>
    <figure  type="picture" id="picture:analysis/too-dense">
        <figcaption>zbyt małe agregacje - niepotrzebnie zbyt wiele punktów zostanie wyrysowanych w jednym pikselu
        </figcaption>
        <img src="/images/analysis/1-too-dense.png" alt="missing"/>
    </figure>
    <figure  type="picture" id="picture:analysis/almost-ok">
        <figcaption>prawie dobrze, ale, wciąż dwa punkty przypadają na jeden piksel</figcaption>
        <img src="/images/analysis/2-almost-ok.png" alt="missing"/>
    </figure>
    <figure  type="picture" id="picture:analysis/ok">
        <figcaption>te agregacje są odpowiednie, gdyż w każdym pikselu mieści się jeden punkt</figcaption>
        <img src="/images/analysis/3-ok.png" alt="missing"/>
    </figure>
    <figure  type="picture" id="picture:analysis/too-sparse">
        <figcaption>zbyt obszerne agregacje, nie wszystkie piskele zawierają punkt - niska rozdzielczość zostanie
            zauważona przez użytkownika
        </figcaption>
        <img src="/images/analysis/4-too-sparse.png" alt="missing"/>
    </figure>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; wyzwania</small>
    </h3>
    <p>
        Można więc uznać, że takie rozwiązanie w stu procentach rozwiązuje problem płynnej i nieograniczonej ekploracji
        wielkoskalowych danych pomiarowych w przeglądarce internetowej.
        Niestety, nie wzięliśmy pod uwagę jednego &mdash; ważnego czynnika &mdash; obecności sieci komputerowej.
    </p>
    <p>
        Skoro fragmenty danych ładowane sa na żądanie użytkownika, to będzie on zmuszony oczekiwać na te dane, zanim
        zostaną dostarczone przez sieć z serwera do przeglądarki.
        Nie będzie on w stanie płynnie eksplorować danych.
        Warto wspomnieć, że wg
        <a href="https://www.nngroup.com/articles/response-times-3-important-limits/" target="blank"> Nielsena</a>,
        oczekiwanie na odpowiedź systemu trwające powyżej 0.1 sekundy jest zauważalne i gdy się wydłuża &mdash; znacznie
        obniża się efektywność korzystania z systemu.
    </p>
    <p>
        To właśnie efektywności wizualnej eksploracji danych poświęcona jest moja praca, w ramach której zaproponowałem
        rozwiązanie, którego kolejne ulepszone wersje zostaną poddane subiektywnej ocenie w tej ankiecie.
    </p>
</div>,
<div>
    <h3 class="display-3">Proponowane rozwiązanie </h3>
    <p>
        Rozwiązanie ma na celu sprawienie, by użytkownik eksplorując dane nie doświadczał negatywnych skutków opóźnień
        sieci, żeby możliwie najlepiej ukryć przed nim fakt, że dane, które przegląda, zlokalizowane są na
        odległym serwerze.
        Dzięki temu użytkownicy dokonujący analizy wizualnej danych będą mogli jeszcze efektywniej wykonywać swoją pracę
        i
        tym samym zwiększyć satysfakcję z użytkowania całego systemu.
    </p>
    <p>
        Rozwiązanie zostało zaprojektowane w postaci uniwersalnego modułu (biblioteki) działającego w przeglądarce
        (język <em>JavaScript</em>), który łatwo integruje się z istniejącymi aplikacjami przeglądarkowymi, napisanymi
        również w języku JavaScript.
    </p>
    <p>
        Biblioteka ta, nosząca nazwę <em>"ExploreJS"</em>, zbudowana jest na czterech filarach:
    </p>
    <ul>
        <li>pamięć podręczna agregacji,</li>
        <li>projekcja pamięci podręcznej,</li>
        <li>mechanizmy predykcji,</li>
        <li>optymalizacja zapytań.</li>
    </ul>
    <p>
        W ankiecie zostaniesz poproszony o eksplorację przykładowych danych prezentowanych na interaktywnym wykresie
        liniowym.
        Zostanie poddane ocenie pięć wersji rozwiązania. Pierwszym będzie tzw. rozwiązanie istniejące, później będą już
        rozwiązania ulepszone o kolejne filary.
        Twoim zadaniem będzie dokonać subiektywnej oceny satysfakcji użytkowania każdej wersji względem poprzedniej.
    </p>
</div>



<!--<p>Krótkie wprowadzenie do rodzdziału</p>-->
<!--<h2>Podrozdział testowy pierwszy</h2>-->
<!--<p>Lorem ipsum, dolor sit amet</p>-->
<!--<h2>Podrozdział testowy drugi</h2>-->
<!--<h3>I lepszy</h3>-->
<!--<p>W tabeli <a href="#table:przyklad1"></a> pokazano to i owo.-->
    <!--Natomiast na rysunku <a href="#picture:wykres1"></a> Wykreślono wszystko co się świeci.-->
    <!--Na listingu <a href="#code:example" class="show-page"></a> pokazano fajny fragment kodu.-->
    <!--Zacytuję tutaj nielsena <a href="#bib:jakob1993usability"></a>, są trzy rodzaje limitów czasu.-->
    <!--A inna bibliografia <a href="#bib:dziennik-internautow"></a> mówi co innego.-->
<!--</p>-->


<!--Nawiązać do: http://istc-bigdata.org/index.php/forecache-raising-the-bar-in-big-data-visual-exploration/-->
<!--In many discussions with scientists across a variety of specialties, we have found that interactive visualizations are important tools for helping people make sense of massive amounts of data. In particular, interactive visualizations are critical in the early stages of data analysis, when a scientist is browsing a new, unfamiliar dataset. In a research project, we studied how scientists explore dense multidimensional arrays, such as satellite imagery, so we could learn about technical barriers in their way.-->
<!--We have observed that scientists explore dense array data in a particular way. First, they browse the data using a coarse-grained aggregated view (i.e., a low-resolution view), searching for interesting regions to analyze in more detail. Once they find a region of interest (or ROI), they “zoom in” by retrieving a fine-grained view (i.e., high-resolution view) of this smaller region from the dataset. Using detail-on-demand interfaces in their exploration tools, scientists can thus apply panning and zooming interactions to explore large arrays.-->
<!--However, most interactive exploration tools are unable to scale up to massive datasets. Therefore, one major goal of this project, and in my thesis work, is to make visual exploration of large arrays interactive, where the user (e.g., a scientist) receives visual feedback from the sys- tem within acceptable response time guarantees (e.g., within 500ms or less). However, a critical challenge in this project is that database management systems are not designed for retrieving results at interactive speeds, making them too slow to provide the fast preliminary results needed by a scalable interactive exploration interface.-->


<!--Nawiązać do licznych issues ze skalowalnością tych rozwiązań, moich testów crashowych.-->

<!--<h2>Przykłady użycia</h2>-->
<!--opisać dlaczego i w jaki sposób korzystają z wizualizacji np w monitoringu środowiska-->

<!--<figure type="table" id="table:przyklad1">-->
    <!--<figcaption>Tabela pokazująca jak to powinno wyglądać</figcaption>-->
    <!--<table>-->
        <!--<thead>-->
        <!--<tr>-->
            <!--<th>nazwa</th>-->
            <!--<th>wartość</th>-->
        <!--</tr>-->
        <!--</thead>-->
        <!--<tbody>-->
        <!--<tr>-->
            <!--<td>imię</td>-->
            <!--<td>Adam</td>-->
        <!--</tr>-->
        <!--<tr>-->
            <!--<td>nazwisko</td>-->
            <!--<td>Borowski</td>-->
        <!--</tr>-->
        <!--<tr>-->
            <!--<td>indeks</td>-->
            <!--<td>137252</td>-->
        <!--</tr>-->
        <!--</tbody>-->
    <!--</table>-->
<!--</figure>-->

<!--<figure type="picture" id="picture:wykres1">-->
    <!--<figcaption>Wykres spadania do siadania</figcaption>-->
    <!--<img src="/images/bg.jpg">-->
<!--</figure>-->

<!--<p>Kontunuacja tekstu</p>-->
<!--<figure type="table">-->
    <!--<figcaption>Tabela pokazująca jak to powinno wyglądać</figcaption>-->
    <!--<table>-->
        <!--<thead>-->
        <!--<tr>-->
            <!--<th>nazwa</th>-->
            <!--<th>wartość</th>-->
        <!--</tr>-->
        <!--</thead>-->
        <!--<tbody>-->
        <!--<tr>-->
            <!--<td>imię</td>-->
            <!--<td>Adam</td>-->
        <!--</tr>-->
        <!--<tr>-->
            <!--<td>nazwisko</td>-->
            <!--<td>Borowski</td>-->
        <!--</tr>-->
        <!--<tr>-->
            <!--<td>indeks</td>-->
            <!--<td>137252</td>-->
        <!--</tr>-->
        <!--</tbody>-->
    <!--</table>-->
<!--</figure>-->

<!--<p>Kontunuacja tekstu</p>-->

