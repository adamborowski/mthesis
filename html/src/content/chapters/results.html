<h1 id="chapter:results">Wyniki i możliwe kierunki rozwoju</h1>

<p>
    W tym rozdziale zostaną zaprezentowane wyniki badań przeprowadzonych z użyciem narzędzia przedstawionego w rozdziale
    <a href="#chapter:research-tool"></a>.
    Zostanie dokonana analiza zgodnie z metodologią opisaną w rozdziale <a href="#chapter:methodology"></a>.

    W pierwszej części zostaną podsumowane odpowiedzi na pytania kontrolne zawarte w ankiecie.
    Następnie zostaną omówione oceny użyteczności oraz ich korelacja z obiektywną miarą responsywności systemu.
    W trzeciej części będą analizowane wyniki testów wydajnościowych.
    Na zakończenie sformułowane zostaną wnioski i przedstawione kierunki, w których proponowane rozwiązanie może być
    doskonalone.
</p>


<h2>Odpowiedzi respondentów</h2>

<p>
    W badaniu wzięło udział 35 respondentów, w tym 4 anonimowo i 7 anglojęzycznych<ft>Obliczone na podstawie odpowiedzi
    na pytania otwarte</ft>.
    Do badania zostały indywidualnie zaproszone 72 osoby, dodatkowo rozesłano grupowe zaproszenie do około 200 osób
    pracujących w jednej z trójmiejskich firm informatycznych.
</p>

<p>
    Na pytanie <q>Jak podoba Ci się ankieta</q> najczęściej (18) odpowiadano <q>zaciekawiła mnie</q>.
    Trochę rzadziej (12) udzielano odpowiedzi <q>nieźle</q>.
    Jedna osoba nie potrafiła udzielić odpowiedzi na to pytanie, 3 osoby uznały tę ankietę za męczącą.
    Nikt nie wyraził tutaj znudzenia zaznaczając opcję <q>znudziłem się</q>.
</p>

<p>
    W odpowiedzi na pytanie, czy przedstawiony problem faktycznie istnieje większość (18) osób zgodziła się ze
    stwierdzeniem, że to jest poważny problem wymagający rozwiązania.
    Pozostałe (16) odpowiedzi wskazuje na to, że problem, co prawda istnieje, to nie jest bardzo poważny.
</p>

<p>
    W pytaniu o podobieństwo problematyki do tej występującej w <em>Google Maps</em>, większość (17) osób uznało to za
    ten sam
    problem, kolejne 14 osób widzi pewne podobieństwo, natomiast 2 osoby wyraziły problem z udzieleniem tej odpowiedzi.
</p>

<p>
    W pytaniu (dotyczących programistów) o spotkanie się z zagadnieniem przeglądania danych pomiarowych w przeszłości
    większość ankietowanych (17 i 14) udzieliło pozytywne odpowiedzi.
    Niektórzy respondenci (2) nie mogli tego jednoznacznie stwierdzić, a 6 osób odpowiedziało przecząco.
</p>

<p>
    Na podobne pytanie, ale dotyczące przyszłości, odpowiedzi już są bardziej równomiernie rozłożone.
    Większość osób podejrzewa, że będą miały do czynienia z wizualną eksploracją danych pomiarowych, 8 osób nie mogło
    tego stwierdzić, kolejne 8 odpowiedziały przecząco.
</p>

<p>
    Ostatnie pytanie zamknięte dotyczyło wyrażenia chęci użycia biblioteki <em>ExploreJS</em> w przypadku zaistnienia
    potrzeby.
    Zdecydowana większość (20) wyraziła taką chęć, o ile będzie to możliwe. Dwie osoby wyraziły dużą determinację
    zaznaczając opcję <q>zrobię wszystko, by skorzystać</q>.
</p>

<p>
    Sześć ankiet zostało wysłanych bez udzielania odpowiedzi na pytania otwarte.
    Na pytania kontrolne znalazły się odpowiedzi świadczące o dużym stopniu zrozumienia dziedziny problemu, na przykład:
</p>

<blockquote>The problem is about optimization of the access to the "big data" displayed on the viewer monitor. Data are
    retrieved (queried) from the web-server and optimized in regards to the resolution (data points / pixels
    horizontally). The solution tries to solve the complex issue despite of the real-time data being displayed in
    graphs on the screen of the monitor. There are changes on screen while user jumps forward or backward the
    graph. Those can be noticed not only because of the slow network simulation. It is likely to say, the issue could
    be the big data (~10 GB) accessibility for query algorithm which needs to be real-time combined with the cashed
    data mechanism that can be displayed in less than 0.1 sec. on screen to have unnoticeable data change flow.
</blockquote>
lub też:
<blockquote>
    You're trying to achieve representation of data at different levels of detail with smooth transition in between.
    There's lots of data and you can't pull all of them into the browser at once, so you have to pull only the parts you
    need (or may need in the nearest future) without introducing lags visible to the user.
</blockquote>
<p>
    Wśród nadesłanych odpowiedzi znalazły się również mniej wyraziste, jak na przykład <q>huge amount of data</q> lub
    <q>user experience</q>, które mogą wskazywać na brak znajomości dziedziny lub brak komfortu czasowego podczas
    udzielania odpowiedzi.
</p>

<p>
    Na podstawie udzielanych odpowiedzi na pytania kontrolne można stwierdzić duże zaangażowanie w badanie, co zwiększa
    wiarygodność otrzymanych wyników.
</p>

<p>
    Respondenci mogli odpowiedzieć również na pytanie o znane alternatywne rozwiązania.
    Niestety nie udzielono na to pytanie ani jednej konstruktywnej odpowiedzi wskazujące konkretne rozwiązanie.
</p>

<p>
    Na pytanie skierowane do programistów, jak zachęcić do używania biblioteki <em>ExploreJS</em>, udzielano odpowiedzi
    wskazujące na potrzebę dobrej dokumentacji, przykładów integracji z tzw. frameworkami <em>JavaScript</em>, proste
    tutoriale oraz opublikowanie na darmowej, otwartej licencji zezwalające na komercyjne użycie. Wspominano również o
    pokryciu biblioteki testami, dostępie do kodu źródłowego i
    trwałym wsparciu technicznym.
</p>

<h2>Responsywność a użyteczność</h2>

<p>
    W tej części zostanie dokonana ocena rozwiązania pod kątem zwiększenia satysfakcji użytkownika eksplorującego dane.

    Do analizy zostały wykorzystane dwa z trzech dostępnych wykresów (wygenerowane przez narzędzie badawcze &mdash; zob.
    rozdział <a href="#chapter:rt-responses-summary"></a>), które przedstawiają rozkład bezwzględnej oceny kolejnych
    rozwiązań (w skali logarytmicznej) oraz procentowy udział przedziałów responsywności systemu, tj. czasu
    załadowania danych dla widzianego przez użytkownika zakresu.
    Zostało to pokazane na ilustracji <a href="#picture:result-corelation"></a>.
</p>

<figure type="picture" id="picture:result-corelation">
    <figcaption>Zależność między oceną użytkowników a responsywnością systemu.</figcaption>
    <img src="cache/results-corelation.png" width="90%"/>
</figure>

<p>
    Na powyższej ilustracji zaznaczono pięć zależności między zmianą rozkładu ocen o zmianą rozkładu responsywności.
</p>

<p>
    Zależność oznaczona literą <em>A</em> pokazuje, że skrajne złe oceny satysfakcji użytkowników (10-ty percentyl),
    utrzymują się przez trzy kolejne wersje rozwiązania: z pamięcią podręczną, z projekcją pamięci oraz z predykcją.
    Z wykresu responsywności wynika, że tym skrajnym ocenom towarzyszy dość szeroki <em>rękaw</em> czasu odpowiedzi
    systemu sięgającego cztery sekundy.
</p>

<p>
    Zależność <em>B</em> pokazuje, że mediana ocen nie rośnie znacząco przez pierwsze trzy wersje rozwiązania.
    Widać również, że dla tych samych wersji rozwiązania dominującym przedziałem responsywności jest ten sięgający
    jednej sekundy, czyli ten odczuwalny dla użytkownika wg <em>Millera</em> (zob. rozdział <a href="#chapter:ux"></a>).
</p>

<p>
    Literą <em>C</em> oznaczono sytuację, w której oceny generalnie nieznacznie się zwiększyły, pomimo pogorszenia
    statystycznej responsywności &dash; rękaw <q>2s</q> powiększył się kosztem <q>1s</q>, co wskazuje na dłuższe czasy
    oczekiwania na dane.
    Tutaj należy zauważyć, że rozwiązanie z projekcją pamięci różni się tylko tym, że wyświetla progresywnie dane o
    mniejszej rozdzielczości podczas załadowania właściwych danych (zob. rozdział <a
        href="#chapter:theoretical-cache-projection"></a>).
    Należy mieć również na uwadze, że responsywność jest mierzona jako czas od akcji nawigacji użytkownika do
    wyświetlenia jemu dokładnych danych, a fakt istnienia <q>zastępczych</q> danych o niższej rozdzielczości nie jest
    tutaj uwzględniany.
    Nie ma różnicy w implementacji, mogącej wpływać na pogorszenie responsywności, zatem można więc wnioskować, że
    lepsze ocenianie wersji o statystycznie gorszej responsywności spowodowane jest właśnie tym progresywnym ładowaniem
    danych, które może być postrzegane jako szybsze działanie systemu <a href="#bib:conference"></a> <ft>
    Progresywne ładowanie jest jedną z optymalizacji typu <em>early completion</em> omówionej w rozdziale <a
        href="#chapter:ux"></a>.
</ft>.
</p>

<p>
    Kolejną ciekawą zależnością jest ta oznaczona literą <em>D</em>.
    Dla wersji z mechanizmem predykcji można zaobserwować nagły i znaczny wzrost mediany oceny tego rozwiązania.
    Jednocześnie na wykresie responsywności można zaobserwować nagłą zmianę w proporcjach przedziałów responsywności
    systemu.
    Rękawy <q>1s</q> oraz <q>2s</q> niemal zniknęły, natomiast rękaw <em>0s</em> zwiększył się i zajmuje połowę całego
    przedziału.

    Oznacza to, że w jedna na dwie akcje nawigacji użytkownika nie wymagała oczekiwania na załadowanie danych.

    Istnieje jeszcze jedna zależność w tym przypadku.
    Skrajnie negatywne oceny (10-ty percentyl) ponownie się obniżyły.
    Jednocześnie można zauważyć pojawienie się bardzo niepożądanego przedziału responsywności <q>&gt;4s</q>.
    Warto wiedzieć, że wersja z mechanizmem predykcji ma taką cechę, że ładowane są większe zakresy danych, w dodatku
    nie tylko na poziomie na którym <q>znajduje się</q> użytkownik<ft>Więcej na ten temat w rozdziale <a
        href="#chapter:implementation-prediction-models"></a></ft>.
    Fakt pojawienia się tego niekorzystnego przedziału spowodowany jest również tym, że w tej wersji modele predykcji
    ładują dane niezależnie, przez co żądania do serwera są często duplikowane.

</p>

<p>
    Ostatnim z interesujących sytuacji jest sytuacja <em>E</em>, w której ogólna ocena, co prawda nieznacznie, podniosła
    się, a skrajnie negatywna ocena (10-ty percentyl) drastycznie się poprawiła.
    Jednocześnie z analizy wykresu responsywności widać, że niemal zniknął przedział <q>4s</q>, który powstał w
    poprzedniej wersji.
    Warto wiedzieć, że ostatnia wersja rozwiązania optymalizuje komunikację z serwerem, między innymi drastycznie
    zmniejsza niepotrzebny ruch, który powstał w poprzedniej wersji &mdash; implementujące mechanizmy predykcji.
</p>

<p>
    Na podstawie analiz zależności przedstawionych na ilustracji <a href="#picture:result-corelation"></a> można
    potwierdzić istnienie silniej korelacji między subiektywnymi ocenami satysfakcji użytkowników, a obiektywną miarą
    responsywności systemu.

    Zasadne jest stwierdzenie, że oceny są statystycznie wiarygodne, a użytkownicy zauważyli i docenili
    usprawnienia płynności wizualnej eksploracji zaimplementowane w <em>ExploreJS</em>.
</p>




<h2>Koszty optymalizacji</h2>

<p>
    Poprzednia część oceny rozwiązania wykazała wzrost satysfakcji użytkowników eksplorujących dane pomiarowe.
    Nie oznacza to jenak, iż proponowane rozwiązanie nadaje się do użycia w realnych systemach.
    By było to możliwe, należy ocenić, czy poprawa satysfakcji pojedynczego użytkownika nie wiąże się ze zbyt wysokimi
    kosztami ukrytymi w innych miejscach systemu wizualizacji.

    W tym celu zostały wykonane testy wydajnościowe w oparciu o infrastrukturę badawczą opisaną w rozdziale <a
        href="#chapter:rt-perf"></a>.
</p>

<p>
    Wybrano jeden reprezentatywny scenariusz wizualnej eksploracji, obejmujący różne typy
    eksploracji.
    Łączny czas wykonania wszystkich trzydziestu przypadków testowych (5 wersji rozwiązania &times; 6 bibliotek
    wizualizacyjnych) zajął 96 minut.
</p>

<h3>Obciążenie serwera wizualizacji</h3>

<p>
    Na ilustracji <a href="#picture:result-perf-basic-info"></a> pokazano wyniki testów wydajnościowych dotyczące
    obciążenia serwera danych spowodowanych żądaniami danych potrzebnych do eksploracji.
</p>

<figure type="picture" id="picture:result-perf-basic-info">
    <figcaption>Wykresy z podstawowymi wynikami testów</figcaption>
    <img src="/images/research-tool/results-basic-info.png" width="75%"/>
</figure>

<p>
    Na tych wykresach prezentowane są trzy parametry wydajnościowe: łączna liczba aktualizacji komponentu wykresu,
    łączna liczba żądań wysłanych do serwera oraz sumaryczny rozmiar danych pobranych z serwera.
    Wyniki prezentowane są dla każdej wersji rozwiązania, a każda wersja była testowana sześć razy (za każdym razem z
    inną biblioteką wizualizacyjną).
</p>
<p>
    Z powyższych wykresów można wnioskować, że rozwiązanie wyjściowe prezentuje się istotnie lepiej niż
    pozostałe.
    Jest to spowodowane, tym, że implementacja bazowa dopuszcza tylko jedno żądanie do serwera jednocześnie<ft>
    Pozostałe wersje nie anulują żądań ze względu na konstrukcję pamięci podręcznej.</ft>.
    To znaczy, że w momencie, gdy użytkownik zmieni wyświetlany zakres, to bieżące żądanie do serwera jest anulowane i
    nie jest uwzględnione w statystykach.

    Można to uznać za pewne niedopatrzenie przy projektowaniu narzędzia badawczego.

</p>

<p>
    Kolejne dwie wersje (z pamięcią podręczną oraz z projekcją pamięci) prezentują się niemal identycznie, ponieważ
    wspomniana projekcja odbywa się tylko na ekranie użytkownika i nie wpływa na komunikację klient-serwer.
</p>

<p>
    Interesującą pod względem wydajności zdaje się być wersja z mechanizmem predykcji.
    Drastycznie rośnie liczba żądań do serwera i rozmiar przesłanych danych.
    Dzieje się tak dlatego, że modele predykcji niezależnie wysyłają zapytania do serwera, nieraz o te same zakresy
    danych<ft>Więcej na ten temat w rozdziale <a href="#chapter:query-optimization"></a></ft>.

    Z kolei znacznie zmniejsza się łączna liczba aktualizacji komponentu wykresu.
    Jest to spowodowane faktem, że modele predykcji zapewniają dużą dostępność danych podczas nawigacji użytkownika,
    więc wykres nie musi być ponownie aktualizowany po zakończeniu ładowania danych<ft>Więcej o aktualizacji komponentu
    wykresu w rozdziale <a href="#chapter:datasource-viewstate-dynamicprojection"></a></ft>.

</p>

<p>
    Finalna wersja rozwiązania wyraźnie zmniejsza koszty wydajnościowe, ponieważ zmniejsza się liczba żądań, a suma
    rozmiaru pobranych danych wraca do poziomu podobnego do poziomów przed drastycznym skokiem w poprzedniej wersji.
    Jest to spowodowane optymalizacją zapytań, która łączy zapytania na poziomie fizycznym i logicznym, co zostało
    wytłumaczone w rozdziale <a href="#chapter:query-optimization"></a>.
</p>

<h3>Obciążenie klienta wizualizacji</h3>

<p>
    Na ilustracjach <a href="#picture:result-perf-chart-update-1"></a>
    pokazano histogramy czasu aktualizacji dla wszystkich
    użytych bibliotek wykresowych.
    Do porównania zostały przedstawione dane ze skrajnych przypadków testowych &mdash; rozwiązania bazowego oraz
    zoptymalizowanego.
</p>


<p>
    Z poniższych histogramów można stwierdzić, że dla większości bibliotek histogramy czasu aktualizacji zachowują
    podobny kształt, za wyjątkiem <em>VisJS</em>, która w wersji optymalizowanej wielokrotnie aktualizowała się przez
    okres dłuższy niż sekunda, co powoduje zauważalne blokowanie przeglądarki.
    Warto wiedzieć, że biblioteka <em>VisJS</em> jest jedyną testowaną biblioteką o przyrostowym interfejsie
    aktualizacji<ft>Możliwe strategie aktualizacji zostały omówione w rozdziale <a href="#chapter:web-interfaces"></a>.
</ft>.
    W ogólności można stwierdzić, że czasy aktualizacji komponentów wykresów wydłużyły się (histogramy przesunięte w
    prawą stronę).
    Jest to niewątpliwie spowodowane tym, że <em>ExploreJS</em> stara się aktualizować komponenty większymi zakresami
    danych (zob. rozdział <a href="#chapter:datasource-viewstate-dynamicprojection"></a>).
</p>


<figure type="picture" id="picture:result-perf-chart-update-1">
    <figcaption>Histogram czasu aktualizacji bibliotek wizualizacyjnych</figcaption>
    <img src="/images/research-tool/result-perf-chart-update-1.png" width="85%"/>
    <img src="/images/research-tool/result-perf-chart-update-2.png" width="85%"/>
    <img src="/images/research-tool/result-perf-chart-update-3.png" width="85%"/>
</figure>

<p>
    Na podstawie powyższych histogramów można stwierdzić, że najmniejsze zużycie procesora można uzyskać stosując
    rozwiązanie <em>ExploreJS</em> z bibliotekami <em>Flot</em>, <em>Plotly</em> oraz <em>Dygraphs</em>, gdyż
    czasy ich aktualizacji w znacznej większości są mniejsze niż <em>0.1s</em>, co stanowi pierwszy limit czasu
    responsywności wg <em>Millera</em> (zob. rozdział <a href="#chapter:ux"></a>).
</p>

<p>
    Ostatnim mierzonym kosztem po stronie klienta jest zużycie pamięci.
    W tym celu analizuje się rozkład zajętości pamięci cache w chwili zakończenia testu.
    Na ilustracji <a href="#picture:result-perf-cache-fill"></a> pokazano liczby elementów pamięci podręcznej na każdym
    poziomie agregacji dla każdej wersji rozwiązania prócz bazowej, która nie posiada pamięci podręcznej.
</p>

<figure type="picture" id="picture:result-perf-cache-fill">
    <figcaption>Rozkład zajętości pamięci podręcznej</figcaption>
    <img src="/images/research-tool/result-perf-cache-fill.png"/>
</figure>

<p>

    Z powyższych danych można obliczyć, że zajętość pamięci podręcznej dla wersji z projekcją jest taka sama jak
    dla podstawowej wersji z pamięcią podręczną, a wersja finalna ma taką samą zajętość jak wersja z predykcją.
    Jest to zrozumiałe, gdyż tylko wersja z mechanizmem predykcji wprowadza logikę wpływającą na pobieranie dodatkowych
    danych do pamięci <em>cache</em>.
</p>

<p>
    Na podstawie tych histogramów można stwierdzić, że kosztem zastosowania mechanizmu predykcji jest około 2.73-krotny
    wzrost użycia pamięci operacyjnej użytkownika.
</p>

<h2>Wnioski</h2>

<p>
    Przystosowanie biblioteki <em>ExploreJS</em> do użycia w realnych systemach wizualizacji zależy w pewnym sensie od
    typu danego systemu, jego fazy rozwoju czy krytyczności.

    Pokazane w poprzednim rozdziale wyniki testów wydajnościowych pokazują, że koszty zastosowania rozwiązania są
    racjonalne i akceptowalne w większości zastosowaniach.
</p>

<p>
    W nawiązaniu do wymagań względem oprogramowania, należy zauważyć, że cały kod źródłowy rozwiązania jest udostępniony
    na otwartej i darmowej licencji <em>MIT</em>.
    Wszystkie moduły i algorytmy zastosowane w rozwiązaniu są pokryte testami jednostkowymi.
    Na tym etapie nie ma jeszcze dokumentacji użytkownika, czy prostych przykładów użycia biblioteki <em>ExploreJS</em>.

    Rozwiązanie wspiera wszystkie przeglądarki i wersje języka <em>JavaScript</em>, nie narzuca również architektury
    systemu wizualizacji.
</p>

<p>
    Została pokazana korelacja między użytecznością postrzeganą przez użytkowników, a obiektywną miarą responsywności
    systemu.
    Udowodniono, że proponowane mechanizmy pamięci podręcznej i predykcji akcji użytkownika upłynniły wizualną
    eksplorację danych. Na rysunku <a href="#picture:result-perf-corelation"></a> pokazano wykres warstwowy procentowego
    udziału przedziałów responsywności systemu, pozyskany z testów wydajnościowych.
</p>


<figure type="picture" id="picture:result-perf-corelation">
    <figcaption>Rozkład responsywności systemu podczas testóww wydajnościowych &mdash;
        kolorem zaznaczono kolejno, licząc od najciemniejszego, przedziały <em>0s</em>,
        <em>&lt;0.1s</em>,
        <em>&lt;1s</em>,
        <em>&lt;2s</em>
        oraz <em>&lt;4s</em>
    </figcaption>
    <img src="/images/research-tool/result-perf-corelation.png"/>
</figure>

<p>
    Na podstawie powyższego wykresu można stwierdzić, jak bardzo poprawiła się responsywność systemu.

    Rozwiązanie bazowe, czyli referencyjna implementacja typowego prostego klienta wizualizacji, w większości sytuacji,
    bo aż 95%, powodowało oczekiwanie na dane w czasie między <em>0.1s</em> do <em>1s</em>.
    Natomiast zaproponowane w tej pracy rozwiązanie w finalnej wersji w większości przypadków (70%) w ogóle nie powoduje
    oczekiwania na dane, ponieważ te są ładowane wcześniej przez mechanizmy predykcji.
    Oczywiście nadal zdarzają się sytuacje, gdzie mechanizmy predykcji nie przewidziały ruchu użytkownika, ale
    jest ich znacznie mniej, bo tylko w 11% przypadków oczekiwanie na dane trwało mniej niż <em>0.1s</em>, 6% poniżej
    sekundy, 9% poniżej
    dwóch sekund.
</p>

<p>
    Oprócz poprawy miary responsywności, stwierdzono iż progresywne wyświetlane danych, realizowane poprzez projekcję
    pamięci podręcznej, zostało korzystnie zauważone przez użytkowników biorących udział w badaniu.
</p>

<p>
    Można zatem uznać, że biblioteka <em>ExploreJS</em>, działająca w przeglądarce użytkownika, zarządzająca komunikacją
    klienta wizualizacji z serwerem, stosująca mechanizmy pamięci <em>cache</em> oraz <em>prefetch</em>, bardzo
    korzystnie wpływa na płynność swobodnej i nieograniczonej wizualnej eksploracji wielkoskalowych danych pomiarowych,
    ponieważ ukrywa przed użytkownikiem negatywne skutki opóźnień sieci komputerowej.
</p>

<h2 class="keep-after">Możliwe kierunki rozwoju</h2>

<p class="keep-inside keep-after">
    Najbardziej pożądanym kierunkiem rozwoju zaproponowanego w tej pracy rozwiązania jest niewątpliwie dalsza
    próba poprawy responsywności systemu wizualizacji bądź minimalizacja kosztów poprawy tej responsywności.

</p>

<p class="keep-inside">
    W przypadku poprawy skuteczności predykcji, można próbować zastosować model predykcji działający w oparciu o łańcuch
    Markowa, co zostało opisane przy okazji przedstawiania narzędzia <q>ForeCache</q> (zob. rozdział <a
        href="#chapter:foreCache"></a>).

    Dodatkowo można zaimplementować inny model zaproponowany w <em>ForeCache</em> - w oparciu o sygnaturę.

    Dla specyficznego typu danych pomiarowych można, jeszcze na serwerze, dla każdej agregacji dołączać metadane o
    podobnych / analogicznych zakresach danych.
    Dzięki temu modele predykcji działające wewnątrz <em>ExploreJS</em> po stronie przeglądarki, odczytując te metadane
    z pamięci podręcznej, mogą pozyskać informacje o podobnych (sąsiednich lub bardziej szczegółowych) fragmentach i na
    tej podstawie ładować dane.
</p>
<p>
    W celu poprawy wydajności warto zaprojektować mechanizm czyszczenia pamięci <em>cache</em> <trans>garbage
    collector</trans>.
    Na ten moment <em>ExploreJS</em> umożliwia tylko dodawanie nowych danych.
    W sytuacji, gdy aplikacja w przeglądarce korzystająca z <em>ExploreJS</em> działa długi czas (na przykład miesiąc)
    bez zamknięcia, może dość do przekroczenia limitu pamięci operacyjnej komputera dla tej aplikacji, co byłoby
    niekorzystne dla użytkownika.

    Trudność implementacji polega na obliczeniu, jakie dane w jakim momencie powinny być usunięte.

    Intuicja podpowiada tutaj oznaczanie zakresów danych znacznikami czasu odwiedzenia ich przez użytkownika.
    W momencie, gdy zapełnienie pamięci przekroczy ustalony z góry limit, należy usunąć dane, które nie są
    oglądane przez użytkownika.
    W pierwszej kolejności powinny zostać usunięte dane, które były najdawniej odwiedzane.
</p>

<p>
    Poprawę wydajności rozwiązania można próbować uzyskać, manipulując różnymi parametrami wewnętrznymi poszczególnych
    modułów.

    Można badać wpływ tych parametrów na koszty wydajnościowe i stopień responsywności.

    Można między innymi sterować rozmiarem kafla w <em>DataSource</em> (rozdział <a
        href="#chapter:datasource-viewstate-dynamicprojection"></a>), marginesem predykcji (rozdział <a
        href="#chapter:implementation-prediction-models"></a>) oraz czasem buforowania w <em>RequestManager</em> (rozdział
    <a href="#chapter:query-optimization"></a>).


</p>

<p>
    Interesującym kierunkiem rozwoju <em>ExploreJS</em> jest obsługa lokalnych modyfikacji surowych danych w pamięci
    podręcznej.
    Dzięki temu edycja danych pomiarowych korzystająca z wizualnej eksploracji nie wymagałaby zapisywania danych na
    serwerze i
    resetowania pamięci <em>cache</em>.
    Tutaj należy zauważyć, że zadanie nie jest trywialne, gdyż wymagałoby umieszczenia logiki agregowania danych po
    stronie przeglądarki.
    Ponieważ w przeglądarce nie jest możliwe załadowanie wszystkich danych celem wyliczenia potrzebnych agregacji,
    konieczne jest rekurencyjne przeliczanie naruszonych agregacji wyższego rzędu na podstawie agregacji niższego rzędu.
    Na ilustracji <a href="#picture:write-mode"></a> pokazano przykładowy algorytm takiego przeliczania agregacji.
</p>

<figure type="picture" id="picture:write-mode">
    <figcaption>Algorytm przeliczania agregacji naruszoną modyfikacją surowych danych</figcaption>
    <img src="cache/write-mode.png" width="80%"/>
</figure>

<p>
    Pokazano tutaj cztery etapy przeliczania agregacji.
    Czerwonym kolorem oznaczono zmienioną agregację, która narusza agregację następnego rzędu, zaznaczoną kolorem
    żółtym.
</p>

<p>
    W punkcie <em>a)</em> zmieniona agregacja pierwszego rzędu (czerwony kolor) narusza agregację drugiego rzędu (żółty
    kolor).
    W związku z tym naruszona agregacja musi zostać przeliczona.
    Do tego celu wykorzystuje się agregacje pierwszego rzędu: tę zmieniona (czerwoną) oraz pozostałe wchodzące w zakres
    przeliczanej agregacji (kolor niebieski).
</p>
<p>
    W punkcie <em>b)</em> agregacja drugiego rzędu została przeliczona, więc agregacja pierwszego rzędu nie narusza już
    spójności, została pokolorowana na zielono.

    Z kolei przed chwilą przeliczona agregacja drugiego rzędu otrzymała nową wartość, która narusza agregację trzeciego
    rzędu, została więc pokolorowana na czerwono.

    Teraz należy przeliczyć agregację trzeciego rzędu (kolor żółty).
    Do tego celu wykorzystuje się przeliczoną agregacje drugiego rzędu oraz pozostałe wchodzące w zakres (kolor niebieski).
</p>
<p>
    W punkcie <em>c)</em> sytuacja jest analogiczna do punktu <em>b)</em>. Agregacja rzędu czwartego jest przeliczona na
    podstawie przeliczonej agregacji rzędu trzeciego oraz pozostałych z zakresu.
    W punkcie <em>d)</em> agregacja czwartego rzędu została przeliczona, natomiast nie narusza żadnej agregacji, gdyż
    jest ona najwyższego rzędu. W tym miejscu algorytm kończy się.
</p>
<p>
    Niestety, problem przeliczania agregacji stanie się dużo bardziej złożony, gdy poziomy agregacji nie będą wzajemnie
    wielokrotne, przez co nie będzie możliwe bezpośrednie wykorzystanie agregacji niższych rzędów do przeliczenia, gdyż
    agregacje, które tylko częściowo należą do przeliczanego zakresu, zawierają informacje z sąsiedniego zakresu,
    których nie da się wyodrębnić.
    W ogólności metody przeliczania warstw pamięci <em>cache</em> stanowią ciekawą drogę rozwoju <em>ExploreJS</em>.
</p>
