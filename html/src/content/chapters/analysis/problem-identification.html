<p>
    Przedstawiana w tej pracy wizualna eksploracja wielkoskalowych danych pomiarowych wiąże ze sobą zagadnienia z
    czterech dziedzin technologii
    informacyjnych:
</p>

<ul>
    <li>
        <em>wizualizacji informacji</em>, gdyż celem tej eksploracji jest pozyskiwanie wiedzy z graficznie
        prezentowanych danych;
    </li>
    <li>
        <em>aplikacji internetowych</em>, ponieważ wizualizacja odbywa się w przeglądarce internetowej, która łączy się
        ze zdalnym serwerem poprzez sieć komputerową w celu pozyskania danych;
    </li>
    <li><em>Big Data</em>, ponieważ danych do eksploracji jest tak wiele, że ich przetworzenie stanowi wyzwanie
        technologiczne i analityczne;
    </li>
    <li><em>User Experience</em>, czyli aspektu użyteczności i efektywności korzystania z systemu interaktywnego.</li>
</ul>

<p>
    Mówiąc ściślej, zagadnienie to dotyczy płynnego, swobodnego i nieograniczonego przeglądania ogromnych zasobów danych
    pomiarowych.
    Dane te prezentowane są na wykresie liniowym z poziomą osią czasu.

    Nieograniczone przeglądanie danych oznacza, że użytkownik ma dostęp do dowolnego fragmentu danych podczas
    wizualizacji.

    Swobodne przeglądanie danych zakłada łatwość i intuicyjność nawigacji po tych danych.

    Płynność natomiast oznacza, że swobodne i nieograniczone przeglądanie danych nie jest w żaden sposób zakłócane.
    Szczególnie, proces ten nie może być hamowany przez konieczność oczekiwania na potrzebne w wizualizacji dane.
</p>

<p>
    Interakcja użytkownika w wizualnej eksploracji danych ogranicza się do nawigacji po danych, czyli wyboru kolejnego
    fragmentu danych do prezentacji.
    W praktyce nawigacja polega na wykonywaniu spójnych, przyrostowych akcji, które tylko w niewielkim stopniu zmieniają
    oglądany zakres danych <a href="#bib:forecache" chapter="2.2"></a>.
    Dla przykładu, jeżeli użytkownik oglądając szczegółowo niewielki fragment danych zechce zobaczyć duży zakres danych,
    wykonuje serię akcji pośrednich stopniowo zwiększających zakres wyświetlanych danych aż do uzyskania docelowego
    zakresu.
    Innymi słowy, w takiej nawigacji rzadko spotykane są <q>skoki</q> do niepowiązanych zakresów danych.
</p>

<p>
    Nawigacja w wizualizacji danych na ekranie komputera intuicyjnie postrzegana jest przez użytkownika jako poruszanie
    się w przestrzeni danych.
    W związku z tym do określenia rodzaju nawigacji często stosuje się pojęcia wyrażające ruch użytkownika względem
    wizualizacji.
    Na rysunku <a href="#picture:motion-actions"></a> przedstawiono cztery możliwe typy ruchów użytkownika.
</p>

<figure type="picture" id="picture:motion-actions">
    <figcaption>Cztery możliwe typy ruchów w wizualnej eksploracji danych</figcaption>
    <img src="cache/motion-actions.png"/>
</figure>

<p>
    Ruch przybliżenia <trans lang="ang">zoom-in</trans> lub oddalenia <trans lang="ang">zoom-out</trans> odpowiada
    stopniowemu zmniejszaniu lub zwiększaniu wyświetlanego zakresu danych.
    Ruch przesunięcia w lewo lub w prawo <trans lang="ang">pan</trans> odpowiada natomiast stopniowemu przesuwaniu
    zakresu w danym kierunku bez zmiany
    wielkości tego zakresu.
    Sam ruch może odbywać się w sposób różnorodny. Można na przykład przybliżać się bliżej krawędzi wykresu lub bliżej
    jego środka.
</p>

<p>
    Podsumowując &mdash; płynna, swobodna i nieograniczona eksploracja danych postrzegana jest zatem przez użytkownika
    jako wykonywanie
    płynnych ruchów <q>podróżując w świecie</q> danych.
</p>


<h2>Studium przypadku</h2>


<p>
    Aby przybliżyć problematykę wizualnej eksploracji danych pomiarowych o dużej skali, posłużono się przykładem
    takiej eksploracji.
</p>

<p>
    Użytkownik, będący pracownikiem naukowym badającym zjawiska pogodowe na terenie USA, analizuje dane
    meteorologiczne zbierane na stacji meteorologicznej w mieście Everett, która nieprzerwanie od 1941 roku
    rejestrowała dane pogodowe z częstotliwością raz na godzinę, a od roku 1990 już co 10 sekund.
    <!--

    TODO bibliografia
     https://www3.epa.gov/ttn/emc/cem/pems.pdf
     https://www.wunderground.com/history/airport/KPAE/1941/11/27/DailyHistory.html?req_city=Everett&req_state=&req_statename=Washington&reqdb.zip=&reqdb.magic=&reqdb.wmo=
     -->

    Do analizy wykorzystuje dane
    temperatury,
    temperatury odczuwalnej,
    opadu sumarycznego,
    ciśnienia,
    wilgotności,
    prędkości i kierunku wiatru,
    widzialności
    oraz promieniowania UV


    zarchiwizowane w formacie stempla czasowego oraz zmierzonej wartości.

    Interesuje go zbadanie jak najszerszego zakresu danych, wobec tego chciałby w swojej przeglądarce internetowej
    przeglądać cały 76-letni okres danych, by móc zarówno przyglądać się różnym trendom na przestrzeni lat, jak i
    analizować poszczególne incydenty.

</p>
<p>
    Warto obliczyć, jak dużo pomiarów zostało w tym czasie wykonanych:
</p>
<div style="vertical-align: middle; text-align: center">
    <!--9* ((1990-1941)years /1hours + (2017-1990)years/10seconds)-->
    <img src="/images/number-of-data.png" width="250" style="vertical-align: middle;"/> = 770.2 miliony próbek.
</div>
<p>
    Jeśli założyć, że każdy punkt wymaga zapisania daty powstania próbki oraz wartości pomiaru, to na zapisanie
    pojedynczego punktu potrzeba 12 bajtów (8 bajtów na datę w formacie <em>long</em> oraz 4 bajty na
    wartość w formacie zmiennoprzecinkowym).
</p>
<p>
    Biorąc pod uwagę liczbę punktów pomiarowych oraz rozmiar danych pojedynczego punktu,
    do przetworzenia jest aż <em>9.24 GB danych</em>
</p>
<p>
    Zasadne jest podejrzewać, że tak duży rozmiar danych wyklucza możliwość pobrania tych danych do aplikacji w
    przeglądarce.
    Nawet, jeżeli założyć dobre wyposażenie sprzętu użytkownika, to przy dobrym (100Mbps) łączu załadowanie tych
    danych do przeglądarki zajmie prawie <em>13 minut</em>.

    Nawet, jeśli pozwoli się użytkownikowi czekać taki czas na pobranie tych danych z sieci do pamięci podręcznej
    komputera, to czasochłonne wyrysowanie miliarda punktów na wykresie niewątpliwie doprowadzi do awaryjnego wyłączenia
    się
    przeglądarki po kilku minutach lub zablokowania aplikacji przez system.

    Podsumowując &mdash; zasoby potrzebne do tej analizy znaczenie przekraczają zasoby komputera użytkownika.

</p>

<h2 id="chapter:problem-identification">Identyfikacja problemu</h2>

<p>
    Opisana wyżej sytuacja składania do refleksji nad sposobem dostarczania użytkownikowi danych do wizualnej
    eksploracji
    danych o takiej skali.
</p>

<p>
    Warto zauważyć, że o ile należy użytkownikowi umożliwić nieograniczony dostęp do wszystkich danych, to nie jest on w
    stanie przetworzyć każdej pojedynczej próbki pomiarowej z osobna. Jest to oczywiście spowodowane ograniczeniem
    zasobów ludzkiego mózgu.
    W rzeczywistości podczas eksploracji danych człowiek jest w stanie przetworzyć tylko znikomą część informacji
    zawartych w udostępnianych danych.

    Dzieje się tak z powodu uproszczenia przekazu, jakie dokonuje się na ograniczonym rozdzielczością monitorze czy w
    konstrukcji ludzkiego oka, którego rozdzielczość też jest ograniczona<ft> Szacuje się ją na blisko 576 megapikseli
    <a href="#bib:eye-resolution"></a></ft>
    .
</p>
<p>
    Z powyższego można wywnioskować, że z punktu widzenia użytkownika eksplorującego dane nie ma znaczenia, w którym
    miejscu przekazu następuje uproszczenie informacji.

    Natomiast z punktu widzenia projektowania wizualizacji uproszczenie informacji jeszcze przed wysłaniem jej z serwera
    do przeglądarki użytkownika zdaje się być jedynym możliwym rozwiązaniem.

</p>


<p>
    Istniejące systemy wizualizacji danych wykorzystują tę cechę przekazu wizualnego.

    W reakcji na nawigację użytkownika, pobierane są z serwera tylko te fragmenty danych,
    które mają być w danym momencie wyświetlone.
    Istotne jest to, że dane te pobierane są w formie maksymalnie uproszczonej.

    Nie za prostej, by nie było to zauważone przez ludzkie oko, ale takiej, by zminimalizować wielkość przesyłanych
    danych.

    Na rysunku <a href="#picture:analysis-data-reduction"></a> zestawiono ze sobą trzy sytuacje, w których uproszczenie
    przekazu następuje w inny sposób.

</p>

<figure type="picture" id="picture:analysis-data-reduction">
    <figcaption class="">
        Uproszczenie informacji w różnych miejscach przekazu w wizualizacji danych:
        <em>a)</em> &mdash; na ekranie komputera
        <em>b)</em> &mdash; na serwerze, jeszcze przed wysłaniem
        <em>c)</em> &mdash; na serwerze, ale uproszczone bardziej niż by to miało miejsca na ekranie
        &mdash;
        rozmiar strumienia danych został oznaczony grubością strzałek
    </figcaption>
    <img src="cache/aggregation-and-natural-reduction.png">
</figure>

<p>
    W pierwszej sytuacji serwer udostępnia dane nieuproszczone, natomiast uproszczenie następuje dopiero na ekranie
    komputera.

    W drugiej sytuacji serwer upraszcza dane jeszcze przed wysłaniem &mdash; w ten sposób, że obraz uproszczony na
    ekranie pozostaje
    niezmieniony.

    Natomiast w trzeciej sytuacji serwer wysyła zbyt uproszczony przekaz tak, że obraz na ekranie staje się zauważalnie
    uproszczony.

    Warto zwrócić uwagę, że w dwóch pierwszych sytuacjach rozmiar strumienia danych trafiający do użytkownika jest
    identyczny pomimo tego, że rozmiar strumienia wychodzącego z serwera znacznie się różni.

</p>
<p>

    Pożądanym sposobem uproszczenia przekazu jest ten drugi, ponieważ można tutaj zredukować transmisję danych przy
    zachowaniu niezmienionej wizualizacji.

    Należy też pamiętać, by tak jak w trzeciej sytuacji, nie upraszczać zbytnio przekazu na serwerze.

    W ogólności zależności między uproszczeniem na serwerze i uproszczeniem na ekranie komputera można wyrazić wzorem <a
        href="#code:simplification-eq"></a>. Oznacza to, że uproszczenie na ekranie danych surowych musi mieć taki sam
    efekt wizualny jak uproszczenie na ekranie danych uproszczonych na serwerze.


</p>

<figure type="code" id="code:simplification-eq">
    <figcaption>Zależność między uproszczeniami:
        <em>U<sub>e</sub></em>&mdash; obraz powstały w wyniku uproszczenia na ekranie,
        <em>U<sub>s</sub></em>&mdash; obraz powstały w wyniku uproszczenia na serwerze,
        <em>d</em> &mdash; strumień danych
    </figcaption>
    <pre code="math">
        U<sub>e</sub>(d) = U<sub>e</sub>(U<sub>s</sub>(d))
    </pre>
</figure>

<p>
    Warto też zauważyć, że przy zastosowaniu odpowiedniego uproszczenia przekazu na serwerze,
    rozmiar danych pobieranych do przeglądarki nie zależy od wielkości przeglądanego zakresu.
    Zależy on od rozmiaru wizualizacji na ekranie, który jest raczej stały.
</p>
<p>
    Takie projektowanie wizualizacji umożliwia swobodną i nieograniczoną eksplorację danych pomiarowych przy
    jednoczesnym zachowaniu stałego, niewielkiego rozmiaru strumienia danych przekazywanych z serwera do przeglądarki.
</p>

<h3>Uproszczenie przekazu</h3>

<p>
    Uproszczenie danych pomiarowych wyświetlanych na wykresie z osią czasu sprowadza się
    uproszczenia grup danych, których zakres po odwzorowaniu przestrzeni czasu na poziomą oś wykresu mieści się w
    jednym, tym samym pikselu.

    Można powiedzieć, że przy dużym zagęszczeniu danych wiele próbek zostaje wyrysowanych na tym samym pionie pikseli,
    tak jak to pokazano na ilustracji <a href="#picture:analysis/simplification"></a>.
</p>

<figure type="picture" id="picture:analysis/simplification">
    <figcaption>
        Gdy na jeden piksel przypada dużo punktów do wyświetlenia (po lewej), to i tak monitor wyświetli to
        jako pionowy <q>słupek</q> obejmujący występujące w tym pikselu wartości (po prawej)
    </figcaption>
    <img src="/images/analysis/simplification.png" height="200"/>
</figure>

<p>
    Podczas rysowania danych na ekranie, linia prowadzona między punktami w ramach jednego pionu pikseli tak naprawdę
    spowoduje zapalanie się wszystkich pikseli mieszczących się w przedziale wartości tych punktów wykresu.
</p>

<p>
    W związku z tym, uproszczoną formą danych pomiarowych rysowanych na tym samym pionie pikseli może być przedział
    wartości próbek, który posłuży do wyrysowania pojedynczego <q>słupka</q>, który będzie wyglądał tak, jakby
    powstał z nakładania się pionowych linii prowadzonych między oryginalnymi punktami.
</p>

<p>
    W celu głębszego zrozumienia działania tego typu uproszczenia należy przedstawić pojęcie <em>agregacji danych</em>
    pomiarowych.
</p>

<p>
    W przypadku danych pomiarowych &mdash; agregacja to struktura opisująca generalne cechy grupy danych z ustalonego
    zakresu.
    Do agregowania, czyli obliczania agregacji, wykorzystuje się <em>agregaty</em> - funkcje matematyczne wyliczające
    określoną statystykę.
    W systemach wizualizacji danych popularnymi agregatami są funkcje minimum, maksimum oraz wartość średnia <a
        href="#bib:siwz"></a>. Agregacja przedstawiona w sposób słowny może wyglądać następująco:
</p>
<blockquote>W sierpniu 2017 roku maksymalna temperatura wyniosła 33&deg;C, minimalna 15&deg;C, a średnia 21.34&deg;C.
</blockquote>
<p>
    Jest to zbiór, który w prosty i zwięzły sposób opisuje najważniejsze ogólne cechy zakresu pomiarów
    dokonanych w sierpniu 2017 i nadaje się jako uproszczona forma danych, o ile zakres tych danych po odwzorowaniu na
    ekran będzie mieścił się w pojedynczym pikselu, jak to zostało omówione wcześniej w tym rozdziale.
</p>

<p>
    Aby eksploracja danych była płynna, warunkiem koniecznym jest możliwie krótki czas odpowiedzi serwera na każde
    żądanie.

    W tym celu serwer musi przygotować agregacje (formy uproszczone), zanim zostanie o nie poproszony, ponieważ
    obliczenie agregacji dla większych zakresów może trwać zbyt długo.
</p>

<p>
    Najprostsze rozwiązanie można wykonać korzystając ze zwykłej relacyjnej bazy danych.
    Wystarczy, że stworzy się jedną tabelę oryginalnych próbek oraz tabelę dla zagregowanych wartości.
    Pierwsza tabela zawierałaby identyfikator serii pomiarowej, czas wykonania próbki oraz zmierzoną wartość.
    Druga tabela zawierałaby identyfikator serii pomiarowej, identyfikator poziomu agregowania, początek oraz koniec
    zakresu agregacji oraz kolumny związane z wybranymi agregatami.
    Dodatkowo należy założyć odpowiednie indeksy by odpytywanie zakresu było efektywne.
    W bazie danych <em>PostgreSQL</em> w wersji 9.3 można skorzystać ze specjalnego typu <em>Range</em>, którego
    oczekiwane indeksowanie jest zapewnione przez bazę danych <a href="#bib:postgresql-range" chapter="8.17"></a>.
</p>

<p>
    Pozostaje jeszcze zaimplementowanie mechanizmu wyliczania agregacji podczas wpisywania próbek do bazy.
    Dla każdego pomiaru, dla każdego wspieranego poziomu agregacji tworzy się instancję modułu, który działa przez
    cały czas pracy systemu, a którego zadaniem jest przyjmowanie każdej nowej próbki do bufora, w momencie gdy dane w
    buforze będę reprezentowały kompletny zakres agregacji, obliczane są wszystkie statystyki, agregacja zostaje
    zapisana w bazie, a bufor jest czyszczony, by być w gotowości do obliczenia kolejnej agregacji.

    Powyższy mechanizm został zilustrowany na rysunku <a href="#picture:aggregation-on-server"></a>.
</p>

<figure type="picture" id="picture:aggregation-on-server">
    <figcaption>
        System akwizycji danych dostarczający potrzebnych agregacji do bazy danych
        &mdash; grubość strzałki symbolizuje wielkość strumienia danych pomiarowych

    </figcaption>
    <img src="cache/aggregation-on-server.png" width="100%"/>
</figure>


<p>
    Istnieje wiele rozwiązań kompleksowo wspierających agregowanie danych w bazie danych, jak na przykład
    <em>KariosDB</em>, <em>OpenTSDB</em> czy <em>InfluxDB</em><ft>InfluxDB został opisany w rozdziale <a href="#chapter:influx"></a>. </ft>.

    Ważne jest to, żeby serwer udostępniał agregacje o różnych wielkościach tak, by mogły służyć za uproszczenia w
    wizualnej eksploracji danych.
    Dostępne poziomy agregacji powinny równomiernie pokrywać przedział skali wizualizacji.
    Mogą to być na przykład agregacje <em> 30s</em>,
    <em> 1m</em>,
    <em> 3m</em>,
    <em> 10m</em>,
    <em> 30m</em>,
    <em> 1h</em>,
    <em> 4h</em>,
    <em> 8h</em>,
    <em> 12h</em>,
    <em> 1d</em>,
    <em> 7d</em>,
    <em> 30d</em>,
    <em> 90d</em>
    oraz
    <em> 1y</em>.
</p>

<p>
    W przeciwnym wypadku dosyć często mogą się zdarzyć sytuacje, w których nie będzie można dobrać takiej agregacji
    do wizualizacji, by rozmiar pobieranych danych był stały. Na rysunku <a href="#picture:aggregation-choice"></a>
    pokazano te sytuacje i ich wpływ na rozmiar pobieranych danych lub wyświetlany obraz.
    <em>A</em> &mdash; zbyt małe agregacje - niepotrzebnie zbyt wiele punktów zostanie wyrysowanych w jednym
    pikselu;
    <em>B</em> &mdash; nieco większe agregacje, ale wciąż dwa punkty przypadają na jeden piksel;
    <em>C</em> &mdash; idealnie, ponieważ w każdym pikselu mieści się jeden punkt;
    <em>D</em> &mdash; zbyt obszerne agregacje, punkty rysowane są co kilka pikseli, a niska rozdzielczość wizualizacji
    zostanie zauważona przez użytkownika.
</p>


<figure type="picture" id="picture:aggregation-choice">
    <figcaption>
        Wpływ wyboru poziomu agregacji na rozmiar pobieranych danych oraz wyświetlany obraz
    </figcaption>
    <img src="cache/aggregation-choice.png"/>
</figure>


<h3>Rozproszenie systemu a <em>User Experience</em></h3>

<p>
    Można więc uznać, że opisane wcześniej podejście do składowania, przekazywania i wyświetlania danych całkowicie
    rozwiązuje problem swobodnej i nieograniczonej wizualnej eksploracji wielkoskalowych danych pomiarowych w
    przeglądarce internetowej.

    Niestety, nie poruszono tutaj jeszcze jednego istotnego aspektu wpływającego na płynność eksploracji &mdash;
    opóźnień w przekazie spowodowanych wolną transmisją danych w sieci komputerowej.
</p>
<p>
    Skoro fragmenty danych ładowane sa na żądanie użytkownika, to będzie on zmuszony oczekiwać na te dane, zanim
    zostaną dostarczone przez sieć z serwera do przeglądarki.
    Nie będzie on w stanie płynnie eksplorować danych.


    Warto przypomnieć, że oczekiwanie na odpowiedź systemu trwające powyżej 0.1 sekundy jest zauważalne i gdy się
    wydłuża &mdash; znacznie obniża się efektywność korzystania z systemu (zob. r. <a href="#chapter:ux"></a>).

    W związku z tym systemy z interfejsami pozwalającymi na operowanie na danych (w tym przypadku ich przeglądanie)
    powinny być tak zoptymalizowane, żeby postrzegany czas reakcji na akcje użytkownika był jak najmniejszy.
</p>
<p>
    Problem oczekiwania na dane jest w systemach rozproszonych dość powszechny.
    Na przykład w systemach obliczeń wysokiej wydajności <trans lang="ang">high performance computing</trans>
    opóźnienia mają bezpośredni wpływ na czas obliczeń.
    Optymalizacja transferu danych ma tutaj kluczową rolę, gdyż często opóźnienia zajmują kilkadziesiąt procent czasu
    wykonania programu, który wykonuje się godzinami, a nawet dobami.
    Motywacja stojąca za optymalizacją transmisji danych w wizualnej eksploracji danych jest nieco inna, gdyż
    optymalizacja ta nie ma na celu skrócić czasu pracy jakiś długotrwałych obliczeń, ale zwiększyć płynność
    wizualizacji, czyli sprawić, by użytkownik nie był rozpraszany podczas eksploracji, by nie była ona hamowana przez
    wolne połączenie, w końcu &mdash; by użytkownik pracował wydajniej.

</p>

<p>
    Techniki stosowane w systemach rozproszonych, mające na celu zminimalizowanie negatywnego wpływu obecności sieci,
    zdają się być adekwatne również do optymalizacji wizualizacji. Wyróżnia się trzy podstawowe metody optymalizacji
    transmisji danych <a href="#bib:xu2004caching"></a>:
    wyświetlanie progresywne
    <trans>progressive display</trans>
    ,
    buforowanie <trans lang="ang">caching</trans> oraz wstępne
    pobieranie danych <trans lang="ang"> prefetching</trans> <a href="#bib:multilevel-cache"></a>.
</p>

<p>
    Wyświetlanie progresywne zakłada, że podczas gdy użytkownik czeka na dane, zasadne jest dodatkowe pobranie
    uproszczonej wersji tych danych pod warunkiem, że odpowiedź serwera nadejdzie istotnie szybciej niż właściwe dane <a
        href="#bib:conference"></a>.
    Dzięki temu umysł użytkownika skupia się na interpretacji wstępnych danych, które stopniowo robią się dla niego
    coraz bardziej czytelne. W ten sposób można ukryć opóźnienia sieci przed percepcją człowieka <a href="#bib:multilevel-cache"></a>.
</p>

<p>
    Technika stosowania pamięci podręcznej <trans>cache</trans> zakłada, że dane, które są odczytywane, będą odczytywane
    również w przyszłości.
    Zatem jest zasadne, by wyniki odczytów przechowywać do wykorzystania w późniejszym czasie.

    Dane te mogą pochodzić ze zdalnego źródła lub mogą być wynikiem kosztownych obliczeń.
    Przykład zastosowania pamięci <em>cache</em> w obliczeniach pokazano na przykładzie rekurencyjnego algorytmu
    obliczania wyrazu ciągu <em>Fibonacciego</em> na listingu <a href="#code:recursive-algorithm-cache"></a>.
</p>

<figure type="code" id="code:recursive-algorithm-cache">
    <figcaption>Rekurencyjne obliczanie ciągu Fibonacciego z zastosowaniem pamięci <em>cache</em>
    </figcaption>
    <pre><code class="javascript">
@@include('fibo.js')
</code></pre>
</figure>

<p>
    Dzięki zastosowaniu pamięci <em>cache</em>, złożoność algorytmu zmieniła się z wykładniczej
    <em>o(2<sup>n</sup>)</em>
    na liniową <em>o(n)</em>.
</p>

<p>
    W przypadku wizualnej eksploracji danych zakłada się, że użytkownik wiele razy odwiedza te same miejsca.
    Dzieje się tak często dlatego, że jego działania mają charakter poszukiwawczy.
    Wyszukiwanie konkretnych miejsc niesąsiadujących ze sobą wymagają poruszania między tymi miejscami.
    Pozostaje jeszcze przypomnieć definicję wizualnej eksploracji z początku tego rozdziału, która zakłada, że nawigacja
    jest przyrostowa, więc zakresy danych w kolejnych krokach wizualizacji mają znaczną część wspólną.
</p>

<p>
    Technika stosowania wstępnego pobierania danych <trans>prefetching</trans> zakłada, że istnieje możliwość
    załadowania danych, zanim będą one potrzebne, aby w momencie zaistnienia potrzeby dane były gotowe do
    odczytu.<!--bib?-->
    Kiedy strumień danych jest deterministyczny, co się często zdarza w systemach <em>HPC</em>,<!--bib?-->
    <em>prefetching</em> polega na skonstruowaniu mechanizmu ładowania, który znając algorytm korzystający z tych danych
    wybiega w przód jego działania i generuje odpowiednie zapytania.
    W przypadku wizualnej eksploracji danych działania użytkownika są niederministyczne, więc znajomość algorytmu
    działania nie jest tutaj wystarczająca.

    Należy doszukiwać się metod, które z pewnym prawdopodobieństwem przewidzą działania użytkownika.
</p>

<p>
    Metody te polegają na predykcji, czyli przewidywaniu zaistnienia potrzeby odczytu określonych danych.
    Predykcja w wizualnej eksploracji opiera swoje działanie na prawdopodobieństwie odwiedzenia danego zakresu danych
    przez użytkownika, Może być obliczana na podstawie śledzenia dotychczasowych akcji użytkownika oraz połączenia
    wiedzy o danych i cech charakterystycznych dla przeglądania danego typu danych (zob. rozdział <a
        href="#chapter:foreCache"></a>).

</p>
<p>
    Na efektywność <em>prefetchingu</em> można wpływać w dwojaki sposób.
    Po pierwsze &mdash; można zastosować mechanizm predykcji o wyższym prawdopodobieństwie przewidywania.
    Kosztem zastosowania tej metody jest trudność projektowania i implementacji danej metody.

    Po drugie &mdash; można ładować więcej danych przy założeniu, że załadowane dane nigdy nie muszą zostać
    wykorzystane.
    W tym przypadku kosztem zastosowania tej metody jest nadmierne wykorzystanie kanału komunikacyjnego, który może być
    wąskim gardłem systemu.

    W związku z tym należy zachować balans miedzy stopniem zaawansowania przewidywania akcji użytkownika a ilością
    dodatkowo ładowanych danych.

    Mechanizmy predykcji zostały szerzej omówione w rozdziale <a href="#chapter:foreCache"></a>.
</p>

<h2>Podsumowanie</h2>

<p>
    Płynna, swobodna i nieograniczona wizualna eksploracja danych w systemie rozproszonym wymaga
    zastosowania technik mających na celu ukrycie przed użytkownikiem faktu obecności sieci komputerowej.
    Dzięki temu użytkownicy dokonujący wizualnej analizy danych będą mogli jeszcze efektywniej wykonywać swoją pracę
    oraz zwiększyć satysfakcję z użytkowania całego systemu.
</p>

<p>
    Zapewnienie dobrego <em>User Experience</em> w aplikacjach użytkowych jest ważnym, choć często kosztownym
    przedsięwzięciem, nieraz wymagającym dodakowego zatrudnienia specjalistów z tej dziedziny.

    Ze względu na ograniczenia zasobów w realizowanych projektach, aspekt ten jest często
    marginalizowany na rzecz dostarczenia priorytetowych funkcji <a href="#bib:ux-ignored"></a>.


    Należy więc znaleźć uniwersalne rozwiązanie problemu płynności wizualnej eskploracji, które można będzie
    stosunkowo niskim kosztem wdrożyć w większości systemów wizualizacji danych pomiarowych, których interfejs coraz częściej
    realizowany jest w przeglądarce internetowej.
</p>

<p>
    W rozdziale <a href="#chapter:existing-solutions"></a> zostaną zaprezentowane takie technologie, algorytmy,
    narzędzia i platformy, które częściowo rozwiązują zidentyfikowany problem płynności eksploracji wizualnej bądź mogą
    być inspiracją zaczerpniętą z innych form wizualizacji.
</p>