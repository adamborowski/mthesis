

<p>
    Przedstawiana w tej pracy wizualna eksploracja wielkoskalowych danych pomiarowych wiąże ze sobą zagadnienia z
    czterech dziedzin technologii
    informacyjnych:
</p>

<ul>
    <li>
        <em>wizualizacji informacji</em>, gdyż celem tej eksploracji jest pozyskiwanie wiedzy z graficznie
        prezentowanych danych;
    </li>
    <li>
        <em>aplikacji internetowych</em>, ponieważ wizualizacja odbywa się w przeglądarce internetowej, która łączy się
        ze zdalnym serwerem poprzez sieć komputerową w celu pozyskania danych;
    </li>
    <li><em>Big Data</em>, ponieważ danych do eksploracji jest tak wiele, że ich przetworzenie stanowi wyzwanie
        technologiczne i analityczne;
    </li>
    <li><em>User Experience</em>, czyli aspektu użyteczności i efektywności korzystania z systemu interaktywnego.</li>
</ul>

<p>
    Mówiąc ściślej, zagadnienie to dotyczy płynnego, swobodnego i nieograniczonego przeglądania ogromnych zasobów danych
    pomiarowych.
    Dane te prezentowane są na wykresie liniowym z osią czasu.

    Nieograniczone przeglądanie danych oznacza, że użytkownik ma dostęp do dowolnego fragmentu danych podczas
    wizualizacji.

    Swobodne przeglądarnie danych zakłada łatwość i intuicyjność nawigacji po tych danych.

    Płynność natomiast oznacza, że swobodne i nieograniczone przeglądanie danych nie jest w żaden sposób zakłócane.
    Szczególnie, proces ten nie może być hamowany przez konieczność oczekiwania na potrzebne w wizualizacji dane.
</p>

<p>
    Interakcja użytkownika w wizualnej eksploracji danych ogranicza się do nawigacji po danych, czyli wyboru kolejnego
    fragmentu danych do prezentacji.
    W praktyce nawigacja polega na wykonywaniu spójnych, przyrostowych akcji, które tylko w niewielkim stopniu zmieniają
    oglądany zakres danych <a href="#bib:forecache" chapter="2.2"></a>.
    Dla przykładu, jeżeli użytkownik oglądając szczegółowo niewielki fragment danych zechce zobaczyć duży zakres danych,
    wykonuje serię akcji pośrednich stopniowo zwiększających zakres wyświetlanych danych aż do uzyskania docelowego
    zakresu.
    Innymi słowy, w takiej nawigacji rzadko spotykane są <q>skoki</q> do niepowiązanych zakresów danych.
</p>

<p>
    Nawigacja w wizualizacji danych na ekranie komputera intuicyjnie postrzegana jest przez użytkownika jako poruszanie
    się w przestrzeni danych.
    W związku z tym do określenia rodzaju nawigacji często stosuje się pojęcia wyrażające ruch użytkownika względem
    wizualizacji.
    Na rysunku <a href="#picture:motion-actions"></a> przedstawiono cztery możliwe typy ruchów użytkownika.
</p>

<figure type="picture" id="picture:motion-actions">
    <figcaption>Cztery możliwe typy ruchów w wizualnej eksploracji danych</figcaption>
    <img src="cache/motion-actions.png"/>
</figure>

<p>
    Ruch przybliżenia <trans lang="ang">zoom-in</trans> lub oddalenia <trans lang="ang">zoom-out</trans> odpowiada
    stopniowemu zmniejszaniu lub zwiększaniu wyświetlanego zakresu danych.
    Ruch przesunięcia w lewo lub w prawo <trans lang="ang">pan</trans> odpowiada natomiast stopniowemu przesuwaniu
    zakresu w danym kierunku bez zmiany
    wielkości tego zakresu.
    Sam ruch może odbywać się w sposób różnorodny. Można na przykład przybliżać się bliżej krawędzi wykresu lub bliżej
    jego środka.
</p>

<p>
    Podsumowując &mdash; płynna, swobodna i nieograniczona eksploracja danych postrzegana jest zatem przez użytkownika
    jako wykonywanie
    płynnych ruchów <q>podróżując w świecie</q> danych.
</p>


<h2>Studium przypadku</h2>


<p>
    Aby przybliżyć problematykę wizualnej eksploracji danych pomiarowych o dużej skali, posłużono się przykładem
    takiej eksploracji.
</p>

<p>
    Użytkownik, będący pracownikiem naukowym badającym zjawiska pogodowe na terenie USA, analizuje dane
    meteorologiczne zbierane na stacji meteorologicznej w mieście Everett, która nieprzerwanie od 1941 roku
    rejestrowała dane pogodowe z częstotliwością raz na godzinę, a od roku 1990 już co 10 sekund.
    <!--
     https://www3.epa.gov/ttn/emc/cem/pems.pdf
     https://www.wunderground.com/history/airport/KPAE/1941/11/27/DailyHistory.html?req_city=Everett&req_state=&req_statename=Washington&reqdb.zip=&reqdb.magic=&reqdb.wmo=
     -->

    Do analizy wykorzystuje dane
    temperatury,
    temperatury odczuwalnej,
    opadu sumarycznego,
    ciśnienia,
    wilgotności,
    prędkości i kierunku wiatru,
    widzialności
    oraz promieniowania UV


    zarchiwizowane w formacie stempla czasowego oraz zmierzonej wartości.

    Interesuje go zbadanie jak najszerszego zakresu danych, wobec tego chciałby w swojej przeglądarce internetowej
    przeglądać cały 76-letni okres danych, by móc zarówno przyglądać się różnym trendom na przestrzeni lat, jak i
    analizować poszczególne incydenty.

</p>
<p>
    Warto obliczyć, jak dużo pomiarów zostało w tym czasie wykonanych:
</p>
<div style="vertical-align: middle; text-align: center">
    <!--9* ((1990-1941)years /1hours + (2017-1990)years/10seconds)-->
    <img src="/images/number-of-data.png" width="250" style="vertical-align: middle;"/> = 770.2 miliony próbek.
</div>
<p>
    Jeśli założyć, że każdy punkt wymaga zapisania daty powstania próbki oraz wartości pomiaru, to na zapisanie
    pojedynczego punktu potrzeba 12 bajtów (8 bajtów na datę w formacie <em>long</em> oraz 4 bajty na
    wartość w formacie zmiennoprzecinkowym).
</p>
<p>
    Biorąc pod uwagę liczbę punktów pomiarowych oraz rozmiar danych pojedynczego punktu,
    do przetworzenia jest aż <em>9.24 GB danych</em>
</p>
<p>
    Zasadne jest podejrzewać, że tak duży rozmiar danych wyklucza możliwość pobrania tych danych do aplikacji w
    przeglądarce.
    Nawet, jeżeli założyć dobre wyposażenie sprzętu użytkownika, to przy dobrym (100Mbps) łączu załadowanie tych
    danych do przeglądarki zajmie prawie <em>13 minut</em>.

    Nawet, jeśli pozwoli się użytkownikowi czekać taki czas na pobranie tych danych z sieci do pamięci podręcznej
    komputera, to czasochłonne wyrysowanie miliarda punktów na wykresie niewątpliwie doprowadzi do awaryjnego wyłączenia
    się
    przeglądarki po kilku minutach lub zablokowania aplikacji przez system.

    Podsumowując &mdash; zasoby potrzebne do tej analizy znaczenie przekraczają zasoby komputera uzytkownika.

</p>

<h2>Identyfikacja problemu</h2>

<p>
    Opisana wyżej sytuacja składania do refleksji nad sposobem dostarczania użytkownikowi danych do wizualnej
    eksploracji
    danych o takiej skali.
</p>

<p>
    Warto zauważyć, że o ile należy użytkownikowi umożliwić nieograniczony dostęp do wszystkich danych, to nie jest on w
    stanie przetworzyć każdej pojedynczej próbki pomiarowej z osobna. Jest to oczywiśćie spowodowane ograniczeniem
    zasobów ludzkiego mózgu.
    W rzeczywistości podczas eksploracji danych człowiek jest w stanie przetworzyć tylko znikomą część informacji
    zawartych w udostępnianych danych.

    Dzieje się tak z powodu uproszczenia przekazu, jakie dokonuje się na ograniczonym rozdzielczością monitorze czy w
    konstrukcji ludzkiego oka, którego rozdzielczość też jest ograniczona
    <ft> Szacuje się ją na blisko 576 megapikseli <a href="#bib:eye-resolution"></a>.</ft>
    .
</p>
<p>
    Z powyższego można wywnioskować, że z punktu widzenia użytkownika eksplorującego dane nie ma znaczenia, w którym
    miejscu przekazu następuje uproszczenie informacji.

    Natomiast z punktu widzenia projektowania wizualizacji uproszczenie informacji jeszcze przed wysłaniem jej z serwera
    do przeglądarki użytkownika zdaje się być jedynym możliwym rozwiązaniem.

</p>


<p>
    Isteniejące systemy wizualizacji danych wykorzystują tę cechę przekazu wizualnego.

    W reakcji na nawigację użytkownika, pobierane są z serwera tylko te fragmenty danych,
    które mają być w danym momencie wyświetlone.
    Istotne jest to, że dane te pobierane są w formie maksymalnie uproszczonej.

    Nie za prostej, by nie było to zauważone przez ludzkie oko, ale takiej, by zminimalizować wielkość przesyłanych
    danych.

    Na rysunku <a href="#picture:analysis-data-reduction"></a> zestawiono ze sobą trzy sytuacje, w których uproszczenie
    przekazu następuje w inny sposób.

</p>

<figure type="picture" id="picture:analysis-data-reduction">
    <figcaption class="text-justify">
        Uproszczenie informacji w różnych miejscach przekazu w wizualizacji danych:
        <em>a)</em> &mdash; na ekranie komputera
        <em>b)</em> &mdash; na serwerze, jeszcze przed wysłaniem
        <em>c)</em> &mdash; na serwerze, ale uproszczone bardziej niż by to miało miejsca na ekranie.
        Rozmiar strumienia danych został oznaczony grubością strzałek.
    </figcaption>
    <img src="cache/aggregation-and-natural-reduction.png">
</figure>

<p>
    W pierwszej sytuacji serwer udostępnia dane nieuproszczone, natomiast uproszczenie następuje dopiero na ekranie
    komputera.

    W drugiej sytuacji serwer upraszcza dane jeszcze przed wysłaniem &mdash; w ten sposób, że obraz uproszczony na
    ekranie pozostaje
    niezmieniony.

    Natomiast w trzeciej sytuacji serwer wysyła zbyt uproszczony przekaz tak, że obraz na ekranie staje się zauważalnie
    uproszczony.

    Warto zwrócić uwagę, że w dwóch pierwszych sytuacjach rozmiar strumienia danych trafiający do użytkownika jest
    identyczny pomimo tego, że rozmiar strumienia wychodzącego z serwera znacznie się różni.

</p>
<p>

    Pożądanym sposobem uproszczenia przekazu jest ten drugi, ponieważ można tutaj zredukować transmisję danych przy
    zachowaniu niezmienionej wizualizacji.

    Należy też pamiętać, by tak jak w trzeciej sytuacji, nie upraszczać zbytnio przekazu na serwerze.

    W ogólności zależności między uproszczeniem na serwerze i uproszczeniem na ekranie komputera można wyrazić wzorem <a
        href="#code:simplification-eq"></a>. Oznacza to, że uproszczenie na ekranie danych surowych musi mieć taki sam
    efekt wizualny jak uproszcenie na ekranie danych uproszczonych na serwerze.


</p>

<figure type="code" id="code:simplification-eq">
    <figcaption>Zależność między uproszczeniami.
        <em>U<sub>e</sub></em>&mdash; obraz powstały w wyniku uproszczenia na ekranie,
        <em>U<sub>s</sub></em>&mdash; obraz powstały w wyniku uproszczenia na serwerze,
        <em>d</em> &mdash; strumień danych.
    </figcaption>
    <pre code="math">
        U<sub>e</sub>(d) = U<sub>e</sub>(U<sub>s</sub>(d))
    </pre>
</figure>

<p>
    Warto też zauważyć, że przy zastosowaniu odpowiedniego uproszczenia przekazu na serwerze,
    rozmiar danych pobieranych do przeglądarki nie zależy od wielkości przeglądanego zakresu.
    Zależy on od rozmiaru wizualizacji na ekranie, który jest raczej stały.
</p>
<p>
    Takie projektowanie wizualizacji umożliwia swobodną i nieograniczoną eksplorację danych pomiarowych przy
    jednoczesnym zachowaniu stałego, niewielkiego rozmiaru strumienia danych przekazywanych z serwera do przeglądarki.
</p>








<p>
    TODO: uwaga duplikacja w rozdziale teoretycznym "Redukcja danych" - najlepiej redukcję przenieśc tylko tutaj i
    rysunek też dać,
    uważnie przeanalizować, który opis lepszy: ten wyżej, czy tamten
</p>



<div>
    <h3 class="display-3">Istniejące rozwiązania</h3>
    <p>
        Pozostaje jeszcze zadać sobie pytanie, czym właściwie jest to uproszczenie?
    </p>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; agregacje</small>
    </h3>
    <p>
        Uproszczona forma danych w naszym przypadku dotyczy tak na prawdę uproszczenia konkretnego piksela wyświetlanego
        wykresu.
        Przy dużym zagęszczeniu danych wiele punktów danych zostaje wyrysowanych na tym samym pionie piskeli, jak
        pokazano
        na rysunku poniżej.

    </p>
    <figure type="picture" id="picture:analysis/simplification">
        <figcaption>
            Gdy na jeden piksel przypada dużo punktów do wyświetlenia (po lewej), to i tak monitor wyświetli to
            jako pionowy słupek obejmujący występujące w tym pikselu wartości (po prawej).
        </figcaption>
        <img src="/images/analysis/simplification.png"/>
    </figure>
    <p>
        W związku z tym, uproszczoną formą danych będzie taka forma, która daje ten sam efekt na ekranie, ale będzie
        opisywała tylko taki pionowy "słupek" opisujący zakres wartości w danej kolumnie pikseli.
        W tym celu wprowadza się pojęcie <strong>agregacji danych</strong>.
    </p>
    <p>
        W tym przypadku agregacja to pewna struktura danych opisująca generalne cechy grupy danych z pewnego zakresu.
        Do obliczenia agregacji wykorzystuje się <em>agregaty</em> - funkcje matematyczne wyliczjące określoną
        statystykę.
        W tego typu systemach popularnymi agregatami są minimum, maksimum oraz wartość średnia.
    </p>
    <p>
        Przykład agregacji:
    </p>
    <blockquote>
        W sierpniu 2017 maksymalna temperatura wyniosła 33&deg;C, minimalna 15&deg;C, a średnia 21.34&deg;C.
    </blockquote>
    <p>
        Jest to zbiór, który w prosty i zwięzły sposób opisuje najważniejsze ogólne cechy zakresu pomiarów
        dokonanych w sierpniu 2017.
    </p>
    <p>
        Tego typu agregacja jest uproszczoną formą danych. Nie oznacza to, że może być wykorzystana w dowolnym momencie.
        Najlepiej ją wykorzystać dla takiej skali wykresu, gdzie będzie ona mieściła się na jednym pionie pikselów
        ekranu.
        Gdy będzie większa - uproszczenie będzie już zauważalne dla ludzkiego oka.
    </p>
    <p>
        Poniżej pokazano ten sam zakres danych, gdy zostały dobrane odpowiednie uproszczenia danych, oraz gdy zastosuje
        się
        zbyt duże uproszczenia. <strong>Uwaga</strong> - należy patrzeć na cieniowany obszar wykresu.
    </p>
    <figure type="picture" id="picture:analysis/per-pixel">
        <figcaption>przykład agregacji o dopasowanej długości, mniejszej niż piksel - nie widać uproszczenia
        </figcaption>
        <img src="/images/analysis/per-pixel.png"/>
    </figure>
    <figure type="picture" id="picture:analysis/sparse">
        <figcaption>przykład źle dobranej agregacji, większej niż jeden piksel - uproszczenie zauważalne dla ludzkiego
            oka
        </figcaption>
        <img src="/images/analysis/sparse.png"/>
    </figure>
    <p>
        Podsumowując - popularne podejście umożliwia swobodną i nieograniczoną eksplorację wielkich zbiorów, ponieważ
        minimalizuje komunikację między przeglądarką a serwerem stosujac takie uproszczenia, by nie zmniejszało
        dokładności danych wyświetlanych na wykresie.
    </p>
</div>,


<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; serwer danych</small>
    </h3>
    <p>
        Warunkiem koniecznym tego rozwiązania jest, aby serwer na każde żądanie mógł odpowiedzieć w bardzo krótkim
        czasie.
        W tym celu serwer musi obliczyć agregacje (formy uproszczone), zanim zostanie o nie poproszony, ponieważ
        obliczenie agregacji dla większych zakresów może trwać zbyt długo.
    </p>
    <p>
        Serwer danych trzyma w specjalnie przygotowanej bazie dane oryginalne (generowane co 10s) (tutaj 9.5GB) oraz
        wyliczone agregacje
        o różnych wielkościach, na przykład
        <em> 30s</em>,
        <em> 1m</em>,
        <em> 3m</em>,
        <em> 10m</em>,
        <em> 30m</em>,
        <em> 1h</em>,
        <em> 4h</em>,
        <em> 8h</em>,
        <em> 12h</em>,
        <em> 1d</em>,
        <em> 7d</em>,
        <em> 30d</em>,
        <em> 90d</em>,
        <em> 1y</em>
        .
    </p>
    <p>
        Ważne jest, by tak dobrać wielkości agregacji, by dla każdego możliwego przybliżenia (skali) wykresu można było
        żądać dane o takiej wielkości agregacji, by odpowiadały blisko, lecz nie więcej niż jednemu pionu pikselów.
        Gdyby tak nie było, trzeba by było żądać mniejszych agregacji, co spowoduje niepotrzebnie zbyt dużą gęstość
        danych
        do wyrysowania na ekranie.
        Z kolei jeśli agregacja nie zmieściła by się w jednym rzędzie pikseli, będzie to widoczne jako reprezentacja
        danych niskiej rozdzielczości.
    </p>
    <figure type="picture" id="picture:analysis/too-dense">
        <figcaption>zbyt małe agregacje - niepotrzebnie zbyt wiele punktów zostanie wyrysowanych w jednym pikselu
        </figcaption>
        <img src="/images/analysis/1-too-dense.png" alt="missing"/>
    </figure>
    <figure type="picture" id="picture:analysis/almost-ok">
        <figcaption>prawie dobrze, ale, wciąż dwa punkty przypadają na jeden piksel</figcaption>
        <img src="/images/analysis/2-almost-ok.png" alt="missing"/>
    </figure>
    <figure type="picture" id="picture:analysis/ok">
        <figcaption>te agregacje są odpowiednie, gdyż w każdym pikselu mieści się jeden punkt</figcaption>
        <img src="/images/analysis/3-ok.png" alt="missing"/>
    </figure>
    <figure type="picture" id="picture:analysis/too-sparse">
        <figcaption>zbyt obszerne agregacje, nie wszystkie piskele zawierają punkt - niska rozdzielczość zostanie
            zauważona przez użytkownika
        </figcaption>
        <img src="/images/analysis/4-too-sparse.png" alt="missing"/>
    </figure>
</div>,
<div>
    <h3 class="display-3">Istniejące rozwiązania
        <small> &raquo; wyzwania</small>
    </h3>
    <p>
        Można więc uznać, że takie rozwiązanie w stu procentach rozwiązuje problem płynnej i nieograniczonej ekploracji
        wielkoskalowych danych pomiarowych w przeglądarce internetowej.
        Niestety, nie wzięliśmy pod uwagę jednego &mdash; ważnego czynnika &mdash; obecności sieci komputerowej.
    </p>
    <p>
        Skoro fragmenty danych ładowane sa na żądanie użytkownika, to będzie on zmuszony oczekiwać na te dane, zanim
        zostaną dostarczone przez sieć z serwera do przeglądarki.
        Nie będzie on w stanie płynnie eksplorować danych.
        Warto wspomnieć, że wg
        <a href="https://www.nngroup.com/articles/response-times-3-important-limits/" target="blank"> Nielsena</a>,
        oczekiwanie na odpowiedź systemu trwające powyżej 0.1 sekundy jest zauważalne i gdy się wydłuża &mdash; znacznie
        obniża się efektywność korzystania z systemu.
    </p>
    <p>
        To właśnie efektywności wizualnej eksploracji danych poświęcona jest moja praca, w ramach której zaproponowałem
        rozwiązanie, którego kolejne ulepszone wersje zostaną poddane subiektywnej ocenie w tej ankiecie.
    </p>
</div>,
<div>
    <h3 class="display-3">Proponowane rozwiązanie </h3>
    <p>
        Rozwiązanie ma na celu sprawienie, by użytkownik eksplorując dane nie doświadczał negatywnych skutków opóźnień
        sieci, żeby możliwie najlepiej ukryć przed nim fakt, że dane, które przegląda, zlokalizowane są na
        odległym serwerze.
        Dzięki temu użytkownicy dokonujący analizy wizualnej danych będą mogli jeszcze efektywniej wykonywać swoją pracę
        i
        tym samym zwiększyć satysfakcję z użytkowania całego systemu.
    </p>
    <p>
        Rozwiązanie zostało zaprojektowane w postaci uniwersalnego modułu (biblioteki) działającego w przeglądarce
        (język <em>JavaScript</em>), który łatwo integruje się z istniejącymi aplikacjami przeglądarkowymi, napisanymi
        również w języku JavaScript.
    </p>
    <p>
        Biblioteka ta, nosząca nazwę <em>"ExploreJS"</em>, zbudowana jest na czterech filarach:
    </p>
    <ul>
        <li>pamięć podręczna agregacji,</li>
        <li>projekcja pamięci podręcznej,</li>
        <li>mechanizmy predykcji,</li>
        <li>optymalizacja zapytań.</li>
    </ul>
    <p>
        W ankiecie zostaniesz poproszony o eksplorację przykładowych danych prezentowanych na interaktywnym wykresie
        liniowym.
        Zostanie poddane ocenie pięć wersji rozwiązania. Pierwszym będzie tzw. rozwiązanie istniejące, później będą już
        rozwiązania ulepszone o kolejne filary.
        Twoim zadaniem będzie dokonać subiektywnej oceny satysfakcji użytkowania każdej wersji względem poprzedniej.
    </p>
</div>

<h3>Podobieństwo do systemów mapowych</h3>


<div>

    <p>
        Ograniczenia i wyzwania można śmiało porównać do systemów mapowych. Dla przykładu, w systemie <em>Google
        Maps </em>
        odwiedzić możesz każde miejsce na ziemi. Za pomocą kilku intuicyjnych ruchów możesz oddalić się od pomnika
        Neptuna
        w Gdańsku, by zobaczyć całą mapę Świata, następnie przyjżeć się z bliska Liberty Island w Nowym Jorku. Wyzwaniem
        w
        takim systemie jest zapewnienie, aby użytkownik w ogóle nie musiał czekać na fragmenty map, które chce oglądać,
        bo
        przecież nikt nie ładuje z sieci Internet szczegółowych obrazów satelitarnych całej kuli ziemskiej.
    </p>
    <p>
        W przypadku danych pomiarowych, można powiedzieć, że problem jest nieco prostszy, ponieważ nie poruszamy się po
        przestrzeni dwuwymiarowej, ale tylko po wymiarze czasu, który układa się na poziomej osi wykresu.
        Niemniej jednak zapewnienie wysokiej rozdzielczości obrazu na wykresie stanowi wyzwanie, jeżeli chcemy, by
        użytkownik jak najrzadziej był zmuszony czekać na doładowanie potrzebnych danych.
        Według <a href="https://www.nngroup.com/articles/response-times-3-important-limits/" target="blank">
        Nielsena</a>,
        oczekiwanie na odpowiedź systemu trwające powyżej 0.1 sekundy jest zauważalne i gdy się wydłuża &mdash; znacznie
        obniża się efektywność pracy.
    </p>
</div>,
<p>Kaflowe systemy mapowe i serie danych pomiarowych mają dużo wspólnych cech:</p>

<figure type="table" id="table:timeseries-geomaps-similarity">
    <figcaption>Zestawienie podobnych cech i zastosowań danych pomiarowych oraz mapowych</figcaption>
    <table>
        <thead>
        <tr>
            <th>cecha</th>
            <th>systemy mapowe</th>
            <th>systemy serii czasowych</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>porządek danych</td>
            <td>przestrzeń geograficzna (2D)</td>
            <td>przestrzeń czasu (1D)</td>
        </tr>
        <tr>
            <td>adresowanie skalowalności</td>
            <td>rozdzielność obrazu satelitarnego</td>
            <td>agregacja danych pomiarowych</td>
        </tr>
        <tr>
            <td>architektura kafli</td>
            <td>fragment przestrzeni geograficznej</td>
            <td>fragment przestrzeni czasu</td>
        </tr>
        <tr>
            <td>aplikacje klienta</td>
            <td>eksploracja terenu</td>
            <td>eksploracja przestrzeni czasu</td>
        </tr>
        </tbody>
    </table>
</figure>


<!--



<p helper>
    W tym rozdziale analizujemy tylko techniczne aspekty problemu, głównie 8 slajdów z survey
    Pokazujemy, co obecnie mamy, potem co takiego brakuje w tym co mamy, na końcu definiujemy wymagania, kryteria akceptacyjne rozwiązania
    Identyfikacja wymagań funkcjonalnych i pozafunkcjonalnych poszukiwanego rozwiązania

    wymagania do rozwiązania, aspekt łatwości integracji z istniejącymi systemami - jakie wykresy do implementacji, które wykresy wziąć pod lupę : https://en.wikipedia.org/wiki/Comparison_of_JavaScript_charting_frameworks
</p>

-->