<h1>Wstęp</h1>

<p>
    Działanie ludzkiej percepcji zmysłowej w dużym stopniu opiera się na analizie informacji dostarczanej przez narząd
    wzroku.
    Wzrokowe przetwarzanie informacji jest dla człowieka pierwotne, naturalne i intuicyjne.
    W ten sposób umysł ludzki jest w stanie efektywnie i równolegle przetwarzać duże ilości danych
    <a href="#bib:laboratorium"></a>, które od wieków służyły ludziom jako podstawowe źródło informacji potrzebnych do
    zrozumienia otaczającego świata, rządzących nim praw oraz pozyskania wiedzy, dzięki której mogli go zmieniać.
    <a href="#bib:wisdom"></a>
</p>
<p>
    Człowiek zaczął mierzyć różne zjawiska na długo przed pojawieniem się komputerów, mogących znacznie mu to ułatwić.
    Można by tutaj wymienić choćby rejestrowanie ruchów sejsmicznych ziemi (1875) <a href="#bib:seismology"></a> .
    Drgający rysik sejsmografu zostawiał ślad na taśmie papierowej nawiniętej na bęben.
    Analitycy ręcznie przeglądali zebrane dane sejsmograficzne, kawałek po kawałku.

    Kiedy pojawiły się komputery i systemy akwizycji danych, zdigitalizowane pomiary przechowywane na lokalnej maszynie
    prezentowane były użytkownikowi w wygodny sposób na monitorze graficznym, a matematyczne metody analizy danych
    wykorzystywano do udzielania ilościowej odpowiedzi na stawiane pytania. Pozwoliło to na znaczne przyśpieszenie
    pracy oraz zwiększenie jakości analizy danych.
</p>
<p>
    Takie wykorzystanie umiejętności ludzi i komputerów nazywa się <i>interaktywną analizą wizualną</i> <trans
        lang="ang">Interactive Visual Analysis</trans>.

    Jest to podejście łączące moc obliczeniową komputerów oraz możliwości percepcyjne i poznawcze ludzkiego mózgu w celu
    wydobycia wiedzy z dużych i skomplikowanych zbiorów danych.

    Istotnym aspektem <abbr>IVA</abbr> jest wizualna eksploracja danych, czyli przeglądanie danych w
    celu znalezienia interesujących fragmentów, postawienia pytania i szukania na nie odpowiedzi zawartej w danych.

</p>
<p>
    Upowszechnienie Internetu jako globalnej sieci wymiany informacji rzuciło nowe wyzwania komputerowej analizie
    danych.
    Trudno jest dzisiaj wyobrazić sobie dziedzinę życia, która nie opierałaby się na gromadzeniu i analizie danych.
    Meteorologia, astronomia, geologia, finanse czy medycyna &mdash; żadne z nich nie mogłoby się bez tego obejść.
    Mniej oczywistych przykładów można doszukiwać się w sporcie, telewizji,
    gospodarstwach domowych czy marketingu zorientowanym na dane <trans lang="ang">data-driven marketing</trans>.
    Mowa tutaj o zbieraniu znacznych rozmiarów danych, które są generowane przez stale obserwowane obiekty.
    Zbierane są informacje o zachowaniu internautów, dane sensorów środowiskowych, obrazy z kamer miejskich, aparatury
    medycznej, czy parametry pracy urządzeń.
    Zastosowanie akwizycji danych na tak szeroką skalę powoduje, że każde urządzenie podłączone do sieci stale
    produkuje znaczną ilość informacji. Jak podał Åse Dragland w artykule z 2013 roku, <cite>90% wszystkich danych na
    świecie zostało wygenerowane przez ostatnie dwa lata</cite> <a href="#bib:dragland2013big"></a>.
    Tendencja eksponencjalnego przyrostu danych w Internecie wydaje się utrzymywać.

    Gromadzenie tak wielkiej ilości danych pozwala osiągnąć wymierne korzyści ekonomiczne, społeczne i naukowe.

    Jednak by móc osiągnąć te korzyści w dobie tak szybkiego przyrostu danych, analiza powinna być dokonana
    na podstawie wiarygodnych, sprawdzonych pomiarów.


</p>

<p>
    Systemy informatyczne, w których krytyczna jest wiarygodność wykonanego pomiaru, posiadają funkcję
    walidacji danych pomiarowych.

    Walidacja ta jest procesem prowadzącym do potwierdzenia autentyczności pomiaru.
    Główym elementem tej walidacji jest analiza dokonywana w celu identyfikacji błędów pomiarowych<ft>Dosyć popularnym
    błędem jest dryft, czyli stopniowe znoszenie wyniku pomiaru.</ft> oraz anomalii środowiska pomiaru<ft>
    Anomalią jest np. rozpalenie ogniska w pobliżu stacji mierzącej parametry jakości powietrza.</ft>.

    Funkcje walidacji w tego typu systemach w większości przypadków sprowadzają się do przeglądania arkuszy danych,
    edycji wartości pomiarów oraz zatwierdzania ich wiarygodności <a href="#bib:data-validation" chapter="p. 9"></a>.

    W walidacji wykorzystuje się również wizualną eksplorację danych <a href="#bib:data-validation" chapter="p. 7"></a>,
    która wykorzystuje zdolności percepcyjne i poznawcze ludzkiego mózgu.

    Stanowi to uzpełnienie tradycyjnych metod, gdzie wizualna eksploracja pozwala lepiej zrozumieć szereg nieoczywistych
    czynników wpływających na powstawanie błędów.

</p>

<p>
    Globalizacja Internetu wymagała też zmiany podejścia do projektowania systemów informatycznych. Zdecydowano się
    rozproszyć dane oraz użytkowników, tworząc aplikacje internetowe, w których użytkownik jest oddalony od
    interesujących go danych.

    O ile ta zmiana nie wpłynęła zasadniczo na wykorzystanie matematycznej analizy komputerowej danych, gdyż serwery
    dokonywały obliczeń odsyłając tylko wyniki do przeglądarki internetowej użytkownika, to w przypadku wizualnej
    eksploracji danych architektura rozproszonych systemów otworzyła nowe możliwości i wyzwania wynikające z odległości
    użytkownika od zasobów, opóźnień sieci czy skali rozmiaru danych udostępnianych przez systemy rozproszone.
</p>

<p>
    Od kilku lat, wraz z rozwojem technologii używanych w przeglądarkach internetowych, coraz większą uwagę przykłada
    się do aspektu użyteczności <trans lang="ang">usability</trans> oraz stosunkowo nowego terminu <em>User
    Experience</em>, co można tłumaczyć na ogół doświadczeń użytkownika korzystającego z interaktywnego interfejsu
    aplikacji.

    Znaczenie zaczęło mieć to, w jaki sposób ludzie korzystają z interfejsów użytkownika.

    Zastanawiano się jak zapewnić dobre wrażenia z użytkowania, na przykład poprzez intuicyjność, łatwość,
    responsywność, a jak minimalizować te złe, takie jak bierne czekanie, niejasność komunikatów, zmiana kontekstu czy
    rozproszenie uwagi.
</p>
<p>
    Popularność dziedziny <em>User Experience</em> pozwala na nowo przyjrzeć się webowym interfejsom użytkownika służącym do
    wizualnej eksploracji wielkoskalowych danych pomiarowych i zbadać je pod tym właśnie kątem.

    Poprawa <em>User Experience</em> w wizualnej eksploracji danych pomiarowych tym samym korzystnie wpłynie na
    efektywność walidacji tych danych poprzez wydajniejszą identyfikację błędów pomiarowych metodami wizualnymi.
</p>
<h2 class="on-new-page">Cel pracy</h2>

<p>
    Celem pracy jest identyfikacja problemów związanych z responsywnością<ft>Responsywność w niniejszej pracy rozumiana
    jest jako specyficzna zdolność systemu do wykonania wyznaczonych zadań w określonym czasie. <a href="#bib:weik2000computer"></a></ft>
    interaktywnego systemu umożliwiającego
    wizualną eksplorację wielkoskalowych danych pomiarowych.

    W pracy zostaną przedstawione główne wyzwania związane z pozyskiwaniem tych danych celem ich wizualnej analizy i ich
    dynamicznej prezentacji.

    Zostanie dokonana analiza istniejących systemów, mechanizmów i algorytmów wspierających tę wizualną eksplorację.

    Zaproponowane zostanie rozwiązanie, które adresuje problem płynności swobodnej i nieograniczonej wizualnej
    eksploracji danych.
</p>
<h2>Treść pracy</h2>
<p>
    Rozdział <a href="#chapter:theoretical"></a> zawiera podstawowe informacje o zagadnieniach związanych danymi
    pomiarowymi oraz ich wizualną eksploracją w systemach rozproszonych.
</p>
<p>
    Rozdział <a href="#chapter:analysis"></a> skupia się na identyfikacji problemu skalowalności wizualnej eksploracji w
    systemach wizualizacji danych pomiarowych.
</p>
<p>
    Rozdział <a href="#chapter:existing-solutions"></a> prezentuje wybrane technologie, algorytmy,
    narzędzia i platformy, które częściowo rozwiązują zidentyfikowany problem bądź są inspiracją zaczerpniętą z
    innych typów systemów.
</p>
<p>
    Rozdział <a href="#chapter:methodology"></a> przedstawia szczegółowe kryteria akceptacyjne rozwiązania
    zidentyfikowanego problemu.
</p>
<p>
    <a href="#chapter:solution">Rozdział</a> wnikliwie prezentuje bibliotekę <em>ExploreJS</em>, stworzoną w ramach tej
    pracy, która umożliwia płynną, swobodną i nieograniczoną wizualną eksplorację wielkoskalowych danych pomiarowych.


    <a href="#chapter:implementation">Rozdział</a> opisuje interesujące fragmenty implementacji zaproponowanego
    rozwiązania.


</p>

<p>
    Rozdział <a href="#chapter:research-tool"></a> przedstawia narzędzie badawcze, stworzone w celu przeprowadzenia
    metodologicznej oceny rozwiązania, przedstawionej w rozdziale <a href="#chapter:methodology"></a>.
</p>
<p>
    Rozdział <a href="#chapter:results"></a> przedstawia uzyskane wyniki, ich metodologiczną ocenę oraz nakreśla
    kierunki dalszego rozwoju biblioteki <em>ExploreJS</em>.
</p>

<p>
    W cytowaniu liczb dziesiętnych użyto separatora w postaci kropki.
</p>