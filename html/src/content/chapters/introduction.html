<h1>Wstęp</h1>

<p>
    Działanie ludzkiej percepcji zmysłowej w dużym stopniu opiera się na analizie informacji dostarczanej przez narząd
    wzroku.
    Wzrokowe przetwarzanie informacji jest więc dla niego pierwotne, naturalne i intuicyjne.
    W ten sposób człowiek jest w stanie efektywnie i równolegle przetwarzać duże ilości danych
    <a href="#bib:laboratorium"></a>, które od wieków służyły mu jako podstawowe źródło informacji potrzebnych do
    zrozumienia otaczającego świata, rządzących nim praw, oraz pozyskania wiedzy, dzięki której mógł wpływać na swoje
    życie. <a href="#bib:wisdom"></a>
</p>
<p>
    Człowiek zaczął mierzyć różne zjawiska na długo przedtem zanim pojawiły się komputery mogące znacznie mu to ułatwić.
    Można by tutaj wymienić choćby rejestrowanie ruchów sejsmicznych ziemi (1875) <a href="#bib:seismology"></a> .
    Drgający rysik sejsmografu zostawiał ślad na taśmie papierowej nawiniętej na bęben.
    Analitycy ręcznie przeglądali zebrane dane sejsmograficzne, kawałek po kawałku.

    Kiedy pojawiły się komputery i systemy akwizycji danych, zdigitalizowane pomiary przechowywane na lokalnej maszynie
    prezentowane były użytkownikowi w wygodny sposób na monitorze graficznym, a matematyczne metody analizy danych
    wykorzystywano do udzielania ilościowej odpowiedzi na stawiane pytania. Pozwoliło to na znaczne przyśpieszenie
    pracy oraz zwiększenie jakości analizy danych.
</p>
<p>
    Takie wykorzystanie umiejętności ludzi i komputerów nazywa się <i>interaktywną analizą wizualną</i> <trans
        lang="ang">Interactive Visual Analysis</trans>.

    Jest to podejście łączące moc obliczeniową komputerów oraz możliwości percepcyjne i poznawcze ludzkiego mózgu w celu
    wydobycia wiedzy z dużych i skomplikowanych zbiorów danych.

    <!--TODO find bib for that - there is somewhere-->
    Jako że interfejs użytkownika z systemem ograniczony jest ekranem komputera, wizualizacja serii
    czasowych realizowana jest poprzez wykreślanie danych z żądanego przez użytkownika okna czasu.

    Warto tutaj wspomnieć o ograniczonej rozdzielczości wyświetlaczy, ludzkiego oka oraz ludzkiej zdolności
    generalizacji szczegółów obrazu.

    Dzięki tym cechom, gdy użytkownik żąda wyświetlenia danych za okres w którym danych jest na tyle dużo, że
    wyświetlenie tych danych w szybkim czasie jest kłopotliwe, wyświetla mu się dane wcześniej zagregowane, a
    użytkownik nie odnotuje różnicy.
</p>
<p>
    Istotnym aspektem <abbr>IVA</abbr> jest wizualna eksploracja danych, czyli przeglądanie danych w
    celu znalezienia interesujących fragmentów, postawienia pytania i szukania na nie odpowiedzi.


    Wizualna eksploracja danych pomiarowych wymaga ciągłej nawigacji po osi czasu, prowadzącej do zmiany zakresu
    wyświetlanych danych.

    Jest to realizowane poprzez nawigację wszerz <trans lang="ang">panning</trans> w której użytkownik przesuwa stałe
    okno czasu w przód lub w tył osi, oraz nawigację wgłąb <trans lang="ang">zooming</trans> polegającą na zmianie
    długości okna czasowego intuicyjnie postrzeganego przez użytkownika jako przybliżenie lub oddalenie od danych.

    Ważnym aspektem wizualnej eksploracji danych jest utrzymanie ciągłości kontekstu nawigacji użytkownika.

    Nawigacja powinna zapewnić podobieństwo widoku danych na tyle duże, żeby człowiek rozpoznał ruch podświadomie.

    Najlepiej, gdy nawigacja realizowana jest poprzez animację, wtedy ludzki mózg postrzega płynny ruch i szybko
    odnotowuje zmianę kontekstu.
    <!--TODO bib about hyman moiton perception-->
</p>
<p>
    Upowszechnienie Internetu jako globalnej sieci wymiany informacji rzuciło nowe wyzwania wizualnej analizie danych.
    Trudno jest dzisiaj wyobrazić sobie dziedzinę życia, która nie opierałaby się na gromadzeniu i analizie danych.
    Meteorologia, astronomia, geologia, finanse czy medycyna &mdash; żadne z nich nie mogłoby się bez tego obejść.
    Mniej oczywistych przykładów można doszukiwać się w sporcie, telewizji,
    gospodarstwach domowych, czy marketingu zorientowanym na dane <trans lang="ang">data-driven marketing</trans>.
    Mowa tutaj o zbieraniu znacznych rozmiarów danych, które są generowane przez stale obserwowane obiekty.
    Zbierane są informacje o zachowaniu internautów, dane sensorów środowiskowych, obrazy z kamer miejskich, aparatury
    medycznej, czy parametry pracy urządzeń.
    Zastosowanie akwizycji danych na tak szeroką skalę powoduje, że każde urządzenie podłączone do sieci stale
    produkuje znaczną ilość informacji. Jak podał Åse Dragland w artykule z 2013 roku, <cite>90% wszystkich danych na
    świecie zostało wygenerowane przez ostatnie dwa lata</cite> <a href="#bib:dragland2013big"></a>.
    Tendencja eksponencjalnego przyrostu danych w Internecie wydaje się utrzymywać.
    Nasuwa się więc pytanie, dlaczego gromadzenie tak wielkiej ilości danych jest potrzebne.
    Według Draglanda analiza tych danych pozwala osiągnąć wymierne korzyści ekonomiczne, społeczne czy naukowe.
</p>
<p>
    Globalizacja Internetu wymagała zmiany podejścia do projektowania systemów informatycznych. Zdecydowano się
    rozproszyć dane oraz użytkowników, tworząc aplikacje internetowe, w których użytkownik jest oddalony od
    interesujących go danych.

    O ile ta zmiana nie wpłynęła zasadniczo na wykorzystanie matematycznej analizy komputerowej danych, gdyż serwery
    dokonywały obliczeń odsyłając tylko wyniki do przeglądarki internetowej użytkownika, to w przypadku interaktywnej
    analizy wizualnej architektura rozproszonych systemów otworzyła nowe możliwości i wyzwania wynikające z odległości
    użytkownika od zasobów, opóźnień sieci czy skali rozmiaru danych udostępnianych przez systemy rozproszone.
</p>
<p>
    Interaktywna analiza wizualna zakłada bowiem swobodę eksploracji danych w czasie. <!--TODO REF-->

    W środowisku rozproszonym jest to o tyle trudne, że czas dostępu do danych potrzebnych do wizualizacji zaczął grać
    znaczącą rolę.

    Skala eksplorowanych danych uniemożliwiła przesyłanie ich w całości celem efektywnego i płynnego operowania.

    Oczywistym stało się, że do użytkownika przesyłany jest tylko podzbiór danych, który jest mu potrzebny w obecnej
    chwili.

</p>
<p>
    Od kilku lat, wraz z rozwojem technologii używanych w przeglądarkach internetowych, coraz większą uwagę przykłada
    się do aspektu użyteczności <trans lang="ang">usability</trans> oraz stosunkowo nowego terminu <trans>User
    Experience</trans>, co można tłumaczyć na ogół doświadczeń użytkownika korzystającego z interaktywnego interfejsu
    aplikacji.

    Znaczenie zaczęło mieć to, w jaki sposób ludzie korzystają z interfejsów użytkownika.

    Zastanawiano się jak zapewnić dobre wrażenia z użytkowania, na przykład poprzez intuicyjność, łatwość, szybkość
    udzielania odpowiedzi na żądanie, a jak minimalizować te złe, takie jak czas biernego oczekiwania, niejasność
    komunikatów, przełączanie kontekstu.
</p>
<p>
    Popularność <trans>User Experience</trans> pozwala na nowo przyjrzeć się webowym interfejsom użytkownika służącym do
    eksploracji w
    wizualnej analizie danych i zbadać je pod tym właśnie kątem.
</p>
<h2 class="on-new-page">Cel pracy</h2>
<p helper="można zmergować">
    Niniejsza praca poświęcona jest problemom, jakie wynikają z przystosowania klasycznych interfejsów użytkownika
    aplikacji webowej do operowania na wielkich zbiorach danych.
    W szczególności mowa o serii danych pomiarowych, których analiza wymaga eksploracji na każdy możliwy sposób.
</p>
<p>
    Celem pracy jest identyfikacja i rozwiązanie problemów związanych z <trans>User Experience</trans> komponentów
    interfejsu użytkownika w przeglądarce internetowej służących do wizualnej eksploracji wielkoskalowych danych
    pomiarowych.

    W pracy zostaną przedstawione główne wyzwania związane z pozyskiwaniem wielkoskalowych danych pomiarowych celem ich
    wizualnej analizy i ich dynamicznej prezentacji.

    Zostanie dokonana analiza istniejących, popularnych webowych komponentów wykresowych pod kątem efektywnej,
    intuicyjnej i sprawnej nawigacji po seriach czasowych.

    Zaproponowane zostanie rozwiązanie, które adresuje problemy skalowalności efektywnej i intuicyjnej eksploracji w
    istniejących komponentach.
</p>
<p helper="do zmergowania">
    Chcemy upłynnić przeglądanie danych (zarządzanie komunikacją klient-serwer) dając jednocześnie swobodę interakcji z
    wielkimi zasobami danych pomiarowych
</p>
<h2>Treść pracy</h2>
<p>
    Rozdział <a href="#chapter:theoretical"></a> zawiera podstawowe informacje o zagadnieniach związanych danymi
    pomiarowymi oraz ich wizualną eksploracją w systemach rozproszonych.
</p>
<p>
    Rozdział <a href="#chapter:analysis"></a> szczegółowo definiuje wymagania <trans>User Experience</trans> względem
    nowoczesnych webowych interfejsów wizualnej eksploracji danych, weryfikuje istniejące rozwiązania pod względem
    spełnienia tych wymagań oraz pod względem dostępności tych rozwiązań dla szerokiego grona twórców aplikacji
    internetowych.

    Pokazuje, że powszechne biblioteki służące do wizualizacji serii czasowych nie spełniają tych wymagań w momencie,
    gdy zostaną wykorzystane do eksploracji danych o dużej skali.

    Rozdział ten przedstawia również w jaki sposób problem skalowalności interfejsu webowego został rozwiązany w
    nowoczesnych
    systemach informacji przestrzennej oraz jakie analogie warunkują możliwość adaptacji tych rozwiązań.
</p>
<p>
    <a href="#chapter:solution">Rozdział</a> wnikliwie prezentuje proponowane rozwiązanie problemu w postaci modułu
    dołączanego do istniejących już bibliotek wizualizacyjnych, który umożliwi im płynną eksplorację wielkoslakowych danych
    pomiarowych.
    Przedstawiona zostaje również metodologia oceny rozwiązania problemu.

    <a href="#chapter:implementation">Rozdział</a> opisuje najciekawsze fragmenty implementacji zaproponowanego
    rozwiązania.

    <a href="#chapter:results">Rozdział</a> przedstawia uzyskane wyniki oraz ich metodologiczną ocenę.
</p>


<ul helper="Pytania pomocnicze">
    <li question="zwiazekZZyciem">jak ma się ta dziedzina do życia dziennego</li>
    <li question="dziedzina">Jakiej dziedziny dotyczy praca <span>big data</span>
        <span>interaktywna wizualizacja </span> <span>frontend</span>
    </li>
    <li question="przedmiotBadan">Co jest badane w pracy magisterskiej, nie wydajne komponenty do rysowania wykresów,
        nie wydajne serwery big data, ale zarządzanie komunikacją klient serwer
        wydajność pracy z danymi

    </li>
    <li question="tloHistoryczne">tło historyczne przedmiotu badań - ważność user experience w wizualizacji danych,
        pierwsze wizualizacje, aplikacje internetowe, cienki gruby klient
        parafrazować Tima Sletchera (technologie serwera)
    </li>
    <li question="tloTechniczne">tło techniczne przedmiotu badań - web performance, big data, trochę więcej o wizualnej
        analizie danych,
        charakterystyka serii czasowych, user experience, web apps, interfejsy webowe w przeglądarce (javascript html),
        webapps: opisać, że wszyscy lubią aplikacje z interfejsem w przeglądarce. Podać przykłady popularnych rozwiązań
        oraz, że migrowały z desktopu: Office live, google docs, photoshop etc...
    </li>
    <li question="tloBranzowe">Tło branżowe przedmioty badań - co to są serie czasowe, po co się je agreguje, jak się z
        tych danych korzysta, jakie są cechy charakterystyczne agregacji - np mogą być wieloktorne lub nieregularne
        przykład że min max średnia - peaks albo sinus

    </li>
    <li question="teza">Jaki realny problem istnieje - teza - obecne biblioteki nie wspierają skalowalności, ale
        mozna im to umozliwic poprzez generyczny mechanizm który by zarządzał źródłem danych dla tych wykresów
    </li>
    <li question="rangaProblemu">istotność tego problemu - nie chodzi o umożliwienie przeglądania danych tylko ux i
        efektywność, jakieś odniesienie od literatury
        slajd 17 z prezentacji 1
    </li>
    <li question="inneDziedziny">dziedziny w których problem występuje, czy już został zaadresowany - google maps
        chociażby
        slajd 18,19,21 prezentacja 1
    </li>
    <li question="alternatywneRozwiazania">kto próbował go rozwiązać w tej dziedzinie - zoomcharts, dygraphs backround,
        forecache -
        slajd 22 perzentacja 1
        co w nich jest niefajnego ze nie rozwiazuje tego problemu, Tim Slatcher
    </li>
    <li>jaki cel ma praca - weryfikacja wsparcia skalowalnosci bibliotek wykresowych. sprawdzenie mozliwosci wsparcia
        skalowalnosci dzięki zaproponowanemu rozwiązaniu,
        Rozwiązanie problemu skalowalności ux interaktywnego interfejsu webowego
    </li>
    <li>proponowane rozwiązanie - jak ono rozwiąże realny problem, nie chodzi o nowe wykresy tylko o wsparcie
        skalowalności dla istniejących - benefity: reuse w istniejacych projektach, tylko jeden adapter i wszystko
        dziala - jakie problemy rozwiaze poszczegolny ficzer (silnik predykcji, cache, projection, dynamicProjection)


        transparentność rozwiązania - minimalizacja wrażeń użytkownika związanych z odległością danych które użytkownik
        przegląda
        tutaj mentionować perception of time - mishunov
        slajd 25 prezentacja 1
        slajd 7 prezentacja 2
        uzasadnienie - podac benefity - polepsza wydajnosc pracy uzytkownikow i robi im dobrze
        wycinek danych - eksploracja w IVA Ze wzgle ̨du na ograniczone moz ̇liwos ́ci ludzkiego mózgu. - nie potrzeba
        lepszych rozwiązań
    </li>
    <li question="tools">Narzędzia i środowiska użyte do realizacji pracy</li>
    <li question="ocena">Metoda ocena przyjętego rozwiązania - nacisk na wydajność i UX, antkiety, perf testy
        slajd 16 prezentacja 2
    </li>

    <li>O czym dalej będzie można przeczytać w tej pracy</li>
</ul>

<h2>Motywacja</h2>

<p helper>
    motywacja (no końcu wstępu)

    problemy napotkane przy realizacji prawdziwego systemu
    * brak generycznych i otwartych rozwiązań
    ** problem wspólny dla wielu aplikacji
    ** niezależność od używanej biblioteki wykresów
    * rosnąca popularność aplikacji w przeglądarkach (ang. Single Page Application)
    * dosyć nowa dziedzina “big data”, “scientific data”

    zakres pracy: nie komponent do rysowania wykresów, nie wydajne serwery big data, efektywne zarządzanie
    komunikacją klient-serwer

</p>

<h2 answer="rangaProblemu">
    Wpływ opóźnienia interakcji w eksploracyjnej analizie wizualnej</h2>
<a href="#bib:effects-interactive-latency"></a>
https://idl.cs.washington.edu/files/2014-Latency-InfoVis.pdf
<blockquote>
    In this research, we have found that interactive latency can play an important
    role in shaping user behavior and impacts the outcomes of exploratory
    visual analysis.z
</blockquote>

